{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHSY/FfNT9c2lttF3GAxfo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fremiud/Proyect2-AI/blob/main/Classification_AI_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIj99HJOQCJJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Network #1\n",
        "class Network1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network1, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 20)\n",
        "        self.fc2 = nn.Linear(20, 50)\n",
        "        self.fc3 = nn.Linear(50, 20)\n",
        "        self.fc4 = nn.Linear(20, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Network #2\n",
        "class Network2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network2, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "        self.fc2 = nn.Linear(10, 20)\n",
        "        self.fc3 = nn.Linear(20, 30)\n",
        "        self.fc4 = nn.Linear(30, 20)\n",
        "        self.fc5 = nn.Linear(20, 10)\n",
        "        self.fc6 = nn.Linear(10, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = torch.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n",
        "\n",
        "# Network #3\n",
        "class Network3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network3, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "        self.fc2 = nn.Linear(10, 40)\n",
        "        self.fc3 = nn.Linear(40, 70)\n",
        "        self.fc4 = nn.Linear(70, 40)\n",
        "        self.fc5 = nn.Linear(40, 10)\n",
        "        self.fc6 = nn.Linear(10, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = torch.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "zcXrsccCQGi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU5EEKMTQH-R",
        "outputId": "da44fe6f-f183-47a1-cd4c-4f16f9e6c309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 334449173.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 34570688.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 163592936.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7327126.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_loader, test_loader):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.view(-1, 28*28)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item()}')\n",
        "\n",
        "    # Evaluation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.view(-1, 28*28)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f'Accuracy of the model on the 10000 test images: {100 * correct / total}% \\n')\n",
        "\n",
        "# Train and evaluate Network #1\n",
        "print(\"Training and evaluating Network #1\")\n",
        "model1 = Network1()\n",
        "train_and_evaluate(model1, train_loader, test_loader)\n",
        "\n",
        "# Train and evaluate Network #2\n",
        "print(\"Training and evaluating Network #2\")\n",
        "model2 = Network2()\n",
        "train_and_evaluate(model2, train_loader, test_loader)\n",
        "\n",
        "# Train and evaluate Network #3\n",
        "print(\"Training and evaluating Network #3\")\n",
        "model3 = Network3()\n",
        "train_and_evaluate(model3, train_loader, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-KAOmpjQKFR",
        "outputId": "dccbcf6f-7ad1-4f08-b13b-89ee358e6a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating Network #1\n",
            "Epoch [1/20], Step [100/600], Loss: 0.5073806643486023\n",
            "Epoch [1/20], Step [200/600], Loss: 0.36304858326911926\n",
            "Epoch [1/20], Step [300/600], Loss: 0.30505791306495667\n",
            "Epoch [1/20], Step [400/600], Loss: 0.2509944438934326\n",
            "Epoch [1/20], Step [500/600], Loss: 0.3524387776851654\n",
            "Epoch [1/20], Step [600/600], Loss: 0.3339536190032959\n",
            "Epoch [2/20], Step [100/600], Loss: 0.21957246959209442\n",
            "Epoch [2/20], Step [200/600], Loss: 0.2244444638490677\n",
            "Epoch [2/20], Step [300/600], Loss: 0.20927129685878754\n",
            "Epoch [2/20], Step [400/600], Loss: 0.3203962743282318\n",
            "Epoch [2/20], Step [500/600], Loss: 0.18484027683734894\n",
            "Epoch [2/20], Step [600/600], Loss: 0.12611006200313568\n",
            "Epoch [3/20], Step [100/600], Loss: 0.18175901472568512\n",
            "Epoch [3/20], Step [200/600], Loss: 0.14030829071998596\n",
            "Epoch [3/20], Step [300/600], Loss: 0.18338371813297272\n",
            "Epoch [3/20], Step [400/600], Loss: 0.2609814703464508\n",
            "Epoch [3/20], Step [500/600], Loss: 0.09255235642194748\n",
            "Epoch [3/20], Step [600/600], Loss: 0.2506883442401886\n",
            "Epoch [4/20], Step [100/600], Loss: 0.1494346559047699\n",
            "Epoch [4/20], Step [200/600], Loss: 0.07924295216798782\n",
            "Epoch [4/20], Step [300/600], Loss: 0.1687086820602417\n",
            "Epoch [4/20], Step [400/600], Loss: 0.22088384628295898\n",
            "Epoch [4/20], Step [500/600], Loss: 0.06315883994102478\n",
            "Epoch [4/20], Step [600/600], Loss: 0.13023896515369415\n",
            "Epoch [5/20], Step [100/600], Loss: 0.268436074256897\n",
            "Epoch [5/20], Step [200/600], Loss: 0.15947534143924713\n",
            "Epoch [5/20], Step [300/600], Loss: 0.30598461627960205\n",
            "Epoch [5/20], Step [400/600], Loss: 0.21135827898979187\n",
            "Epoch [5/20], Step [500/600], Loss: 0.1059398353099823\n",
            "Epoch [5/20], Step [600/600], Loss: 0.2025507539510727\n",
            "Epoch [6/20], Step [100/600], Loss: 0.08377886563539505\n",
            "Epoch [6/20], Step [200/600], Loss: 0.12317883223295212\n",
            "Epoch [6/20], Step [300/600], Loss: 0.1693691462278366\n",
            "Epoch [6/20], Step [400/600], Loss: 0.1592087596654892\n",
            "Epoch [6/20], Step [500/600], Loss: 0.11055223643779755\n",
            "Epoch [6/20], Step [600/600], Loss: 0.03385993838310242\n",
            "Epoch [7/20], Step [100/600], Loss: 0.20525430142879486\n",
            "Epoch [7/20], Step [200/600], Loss: 0.10525093227624893\n",
            "Epoch [7/20], Step [300/600], Loss: 0.17759349942207336\n",
            "Epoch [7/20], Step [400/600], Loss: 0.1073460578918457\n",
            "Epoch [7/20], Step [500/600], Loss: 0.3215727210044861\n",
            "Epoch [7/20], Step [600/600], Loss: 0.031485676765441895\n",
            "Epoch [8/20], Step [100/600], Loss: 0.10420696437358856\n",
            "Epoch [8/20], Step [200/600], Loss: 0.07928489148616791\n",
            "Epoch [8/20], Step [300/600], Loss: 0.05332498252391815\n",
            "Epoch [8/20], Step [400/600], Loss: 0.0937676876783371\n",
            "Epoch [8/20], Step [500/600], Loss: 0.08588263392448425\n",
            "Epoch [8/20], Step [600/600], Loss: 0.13589626550674438\n",
            "Epoch [9/20], Step [100/600], Loss: 0.1372753381729126\n",
            "Epoch [9/20], Step [200/600], Loss: 0.041320279240608215\n",
            "Epoch [9/20], Step [300/600], Loss: 0.1318318247795105\n",
            "Epoch [9/20], Step [400/600], Loss: 0.06616301834583282\n",
            "Epoch [9/20], Step [500/600], Loss: 0.05551070719957352\n",
            "Epoch [9/20], Step [600/600], Loss: 0.11464527994394302\n",
            "Epoch [10/20], Step [100/600], Loss: 0.057758230715990067\n",
            "Epoch [10/20], Step [200/600], Loss: 0.12119968235492706\n",
            "Epoch [10/20], Step [300/600], Loss: 0.12894654273986816\n",
            "Epoch [10/20], Step [400/600], Loss: 0.08410213142633438\n",
            "Epoch [10/20], Step [500/600], Loss: 0.22574394941329956\n",
            "Epoch [10/20], Step [600/600], Loss: 0.12619124352931976\n",
            "Epoch [11/20], Step [100/600], Loss: 0.24259589612483978\n",
            "Epoch [11/20], Step [200/600], Loss: 0.09263746440410614\n",
            "Epoch [11/20], Step [300/600], Loss: 0.09638654440641403\n",
            "Epoch [11/20], Step [400/600], Loss: 0.07410261780023575\n",
            "Epoch [11/20], Step [500/600], Loss: 0.08280107378959656\n",
            "Epoch [11/20], Step [600/600], Loss: 0.16300374269485474\n",
            "Epoch [12/20], Step [100/600], Loss: 0.13760460913181305\n",
            "Epoch [12/20], Step [200/600], Loss: 0.051704809069633484\n",
            "Epoch [12/20], Step [300/600], Loss: 0.07541682571172714\n",
            "Epoch [12/20], Step [400/600], Loss: 0.16723324358463287\n",
            "Epoch [12/20], Step [500/600], Loss: 0.1256788969039917\n",
            "Epoch [12/20], Step [600/600], Loss: 0.14480821788311005\n",
            "Epoch [13/20], Step [100/600], Loss: 0.1621163934469223\n",
            "Epoch [13/20], Step [200/600], Loss: 0.04571051523089409\n",
            "Epoch [13/20], Step [300/600], Loss: 0.059031788259744644\n",
            "Epoch [13/20], Step [400/600], Loss: 0.10984700918197632\n",
            "Epoch [13/20], Step [500/600], Loss: 0.06869067251682281\n",
            "Epoch [13/20], Step [600/600], Loss: 0.14009122550487518\n",
            "Epoch [14/20], Step [100/600], Loss: 0.08735717087984085\n",
            "Epoch [14/20], Step [200/600], Loss: 0.0812513530254364\n",
            "Epoch [14/20], Step [300/600], Loss: 0.19165633618831635\n",
            "Epoch [14/20], Step [400/600], Loss: 0.10161943733692169\n",
            "Epoch [14/20], Step [500/600], Loss: 0.05264156311750412\n",
            "Epoch [14/20], Step [600/600], Loss: 0.11861719191074371\n",
            "Epoch [15/20], Step [100/600], Loss: 0.032564204186201096\n",
            "Epoch [15/20], Step [200/600], Loss: 0.09179071336984634\n",
            "Epoch [15/20], Step [300/600], Loss: 0.08339037746191025\n",
            "Epoch [15/20], Step [400/600], Loss: 0.06995661556720734\n",
            "Epoch [15/20], Step [500/600], Loss: 0.18218088150024414\n",
            "Epoch [15/20], Step [600/600], Loss: 0.07543811947107315\n",
            "Epoch [16/20], Step [100/600], Loss: 0.10038702934980392\n",
            "Epoch [16/20], Step [200/600], Loss: 0.05762526020407677\n",
            "Epoch [16/20], Step [300/600], Loss: 0.25004905462265015\n",
            "Epoch [16/20], Step [400/600], Loss: 0.1769125610589981\n",
            "Epoch [16/20], Step [500/600], Loss: 0.07853103429079056\n",
            "Epoch [16/20], Step [600/600], Loss: 0.05919196456670761\n",
            "Epoch [17/20], Step [100/600], Loss: 0.17458133399486542\n",
            "Epoch [17/20], Step [200/600], Loss: 0.07351791113615036\n",
            "Epoch [17/20], Step [300/600], Loss: 0.08597820997238159\n",
            "Epoch [17/20], Step [400/600], Loss: 0.09252245724201202\n",
            "Epoch [17/20], Step [500/600], Loss: 0.10878179222345352\n",
            "Epoch [17/20], Step [600/600], Loss: 0.09862694889307022\n",
            "Epoch [18/20], Step [100/600], Loss: 0.1299862265586853\n",
            "Epoch [18/20], Step [200/600], Loss: 0.1256023645401001\n",
            "Epoch [18/20], Step [300/600], Loss: 0.076341412961483\n",
            "Epoch [18/20], Step [400/600], Loss: 0.10693777352571487\n",
            "Epoch [18/20], Step [500/600], Loss: 0.12214361876249313\n",
            "Epoch [18/20], Step [600/600], Loss: 0.0749700665473938\n",
            "Epoch [19/20], Step [100/600], Loss: 0.19332312047481537\n",
            "Epoch [19/20], Step [200/600], Loss: 0.14310839772224426\n",
            "Epoch [19/20], Step [300/600], Loss: 0.12612241506576538\n",
            "Epoch [19/20], Step [400/600], Loss: 0.2427385300397873\n",
            "Epoch [19/20], Step [500/600], Loss: 0.1541697084903717\n",
            "Epoch [19/20], Step [600/600], Loss: 0.09614195674657822\n",
            "Epoch [20/20], Step [100/600], Loss: 0.1091339960694313\n",
            "Epoch [20/20], Step [200/600], Loss: 0.1440519392490387\n",
            "Epoch [20/20], Step [300/600], Loss: 0.06254138052463531\n",
            "Epoch [20/20], Step [400/600], Loss: 0.04906584694981575\n",
            "Epoch [20/20], Step [500/600], Loss: 0.20951908826828003\n",
            "Epoch [20/20], Step [600/600], Loss: 0.15703646838665009\n",
            "Accuracy of the model on the 10000 test images: 95.99% \n",
            "\n",
            "Training and evaluating Network #2\n",
            "Epoch [1/20], Step [100/600], Loss: 0.710720956325531\n",
            "Epoch [1/20], Step [200/600], Loss: 0.661967396736145\n",
            "Epoch [1/20], Step [300/600], Loss: 0.29756370186805725\n",
            "Epoch [1/20], Step [400/600], Loss: 0.2602710425853729\n",
            "Epoch [1/20], Step [500/600], Loss: 0.3121938109397888\n",
            "Epoch [1/20], Step [600/600], Loss: 0.3226499855518341\n",
            "Epoch [2/20], Step [100/600], Loss: 0.4762429893016815\n",
            "Epoch [2/20], Step [200/600], Loss: 0.7075408697128296\n",
            "Epoch [2/20], Step [300/600], Loss: 0.2523403465747833\n",
            "Epoch [2/20], Step [400/600], Loss: 0.5211315751075745\n",
            "Epoch [2/20], Step [500/600], Loss: 0.21339476108551025\n",
            "Epoch [2/20], Step [600/600], Loss: 0.16252197325229645\n",
            "Epoch [3/20], Step [100/600], Loss: 0.293127179145813\n",
            "Epoch [3/20], Step [200/600], Loss: 0.27997007966041565\n",
            "Epoch [3/20], Step [300/600], Loss: 0.3849000930786133\n",
            "Epoch [3/20], Step [400/600], Loss: 0.26728355884552\n",
            "Epoch [3/20], Step [500/600], Loss: 0.45512571930885315\n",
            "Epoch [3/20], Step [600/600], Loss: 0.3825282156467438\n",
            "Epoch [4/20], Step [100/600], Loss: 0.22439250349998474\n",
            "Epoch [4/20], Step [200/600], Loss: 0.3215121030807495\n",
            "Epoch [4/20], Step [300/600], Loss: 0.2430175542831421\n",
            "Epoch [4/20], Step [400/600], Loss: 0.2594090402126312\n",
            "Epoch [4/20], Step [500/600], Loss: 0.2645126283168793\n",
            "Epoch [4/20], Step [600/600], Loss: 0.3177599012851715\n",
            "Epoch [5/20], Step [100/600], Loss: 0.13055212795734406\n",
            "Epoch [5/20], Step [200/600], Loss: 0.18345490097999573\n",
            "Epoch [5/20], Step [300/600], Loss: 0.12755745649337769\n",
            "Epoch [5/20], Step [400/600], Loss: 0.34067943692207336\n",
            "Epoch [5/20], Step [500/600], Loss: 0.23167207837104797\n",
            "Epoch [5/20], Step [600/600], Loss: 0.13833661377429962\n",
            "Epoch [6/20], Step [100/600], Loss: 0.15363870561122894\n",
            "Epoch [6/20], Step [200/600], Loss: 0.09574808925390244\n",
            "Epoch [6/20], Step [300/600], Loss: 0.26647916436195374\n",
            "Epoch [6/20], Step [400/600], Loss: 0.24799053370952606\n",
            "Epoch [6/20], Step [500/600], Loss: 0.13145937025547028\n",
            "Epoch [6/20], Step [600/600], Loss: 0.2945159077644348\n",
            "Epoch [7/20], Step [100/600], Loss: 0.30385056138038635\n",
            "Epoch [7/20], Step [200/600], Loss: 0.19213226437568665\n",
            "Epoch [7/20], Step [300/600], Loss: 0.12056609988212585\n",
            "Epoch [7/20], Step [400/600], Loss: 0.20289988815784454\n",
            "Epoch [7/20], Step [500/600], Loss: 0.15347988903522491\n",
            "Epoch [7/20], Step [600/600], Loss: 0.2105524092912674\n",
            "Epoch [8/20], Step [100/600], Loss: 0.19487999379634857\n",
            "Epoch [8/20], Step [200/600], Loss: 0.31109923124313354\n",
            "Epoch [8/20], Step [300/600], Loss: 0.46131080389022827\n",
            "Epoch [8/20], Step [400/600], Loss: 0.2869068682193756\n",
            "Epoch [8/20], Step [500/600], Loss: 0.20890337228775024\n",
            "Epoch [8/20], Step [600/600], Loss: 0.21225959062576294\n",
            "Epoch [9/20], Step [100/600], Loss: 0.24452844262123108\n",
            "Epoch [9/20], Step [200/600], Loss: 0.2046746015548706\n",
            "Epoch [9/20], Step [300/600], Loss: 0.17557790875434875\n",
            "Epoch [9/20], Step [400/600], Loss: 0.12187879532575607\n",
            "Epoch [9/20], Step [500/600], Loss: 0.22173883020877838\n",
            "Epoch [9/20], Step [600/600], Loss: 0.1578574925661087\n",
            "Epoch [10/20], Step [100/600], Loss: 0.1767955720424652\n",
            "Epoch [10/20], Step [200/600], Loss: 0.280135840177536\n",
            "Epoch [10/20], Step [300/600], Loss: 0.36124926805496216\n",
            "Epoch [10/20], Step [400/600], Loss: 0.6097357869148254\n",
            "Epoch [10/20], Step [500/600], Loss: 0.20419099926948547\n",
            "Epoch [10/20], Step [600/600], Loss: 0.26785483956336975\n",
            "Epoch [11/20], Step [100/600], Loss: 0.34736883640289307\n",
            "Epoch [11/20], Step [200/600], Loss: 0.3434806168079376\n",
            "Epoch [11/20], Step [300/600], Loss: 0.22175361216068268\n",
            "Epoch [11/20], Step [400/600], Loss: 0.1645069569349289\n",
            "Epoch [11/20], Step [500/600], Loss: 0.30416834354400635\n",
            "Epoch [11/20], Step [600/600], Loss: 0.3091287314891815\n",
            "Epoch [12/20], Step [100/600], Loss: 0.3291774392127991\n",
            "Epoch [12/20], Step [200/600], Loss: 0.27231287956237793\n",
            "Epoch [12/20], Step [300/600], Loss: 0.22115884721279144\n",
            "Epoch [12/20], Step [400/600], Loss: 0.44892871379852295\n",
            "Epoch [12/20], Step [500/600], Loss: 0.21603603661060333\n",
            "Epoch [12/20], Step [600/600], Loss: 0.12325825542211533\n",
            "Epoch [13/20], Step [100/600], Loss: 0.316433846950531\n",
            "Epoch [13/20], Step [200/600], Loss: 0.459136426448822\n",
            "Epoch [13/20], Step [300/600], Loss: 0.19428721070289612\n",
            "Epoch [13/20], Step [400/600], Loss: 0.20025001466274261\n",
            "Epoch [13/20], Step [500/600], Loss: 0.13208846747875214\n",
            "Epoch [13/20], Step [600/600], Loss: 0.20605602860450745\n",
            "Epoch [14/20], Step [100/600], Loss: 0.24630029499530792\n",
            "Epoch [14/20], Step [200/600], Loss: 0.2629642188549042\n",
            "Epoch [14/20], Step [300/600], Loss: 0.2161434292793274\n",
            "Epoch [14/20], Step [400/600], Loss: 0.2687668800354004\n",
            "Epoch [14/20], Step [500/600], Loss: 0.1747126430273056\n",
            "Epoch [14/20], Step [600/600], Loss: 0.2174026519060135\n",
            "Epoch [15/20], Step [100/600], Loss: 0.11911454051733017\n",
            "Epoch [15/20], Step [200/600], Loss: 0.1636086255311966\n",
            "Epoch [15/20], Step [300/600], Loss: 0.14163076877593994\n",
            "Epoch [15/20], Step [400/600], Loss: 0.24055366218090057\n",
            "Epoch [15/20], Step [500/600], Loss: 0.1436954140663147\n",
            "Epoch [15/20], Step [600/600], Loss: 0.07388992607593536\n",
            "Epoch [16/20], Step [100/600], Loss: 0.2264816164970398\n",
            "Epoch [16/20], Step [200/600], Loss: 0.2353748381137848\n",
            "Epoch [16/20], Step [300/600], Loss: 0.26524820923805237\n",
            "Epoch [16/20], Step [400/600], Loss: 0.3446684181690216\n",
            "Epoch [16/20], Step [500/600], Loss: 0.31657761335372925\n",
            "Epoch [16/20], Step [600/600], Loss: 0.2996197044849396\n",
            "Epoch [17/20], Step [100/600], Loss: 0.22367723286151886\n",
            "Epoch [17/20], Step [200/600], Loss: 0.1508132815361023\n",
            "Epoch [17/20], Step [300/600], Loss: 0.412781685590744\n",
            "Epoch [17/20], Step [400/600], Loss: 0.2753262221813202\n",
            "Epoch [17/20], Step [500/600], Loss: 0.31867122650146484\n",
            "Epoch [17/20], Step [600/600], Loss: 0.2531132400035858\n",
            "Epoch [18/20], Step [100/600], Loss: 0.1948009431362152\n",
            "Epoch [18/20], Step [200/600], Loss: 0.1842298060655594\n",
            "Epoch [18/20], Step [300/600], Loss: 0.17652803659439087\n",
            "Epoch [18/20], Step [400/600], Loss: 0.2649470567703247\n",
            "Epoch [18/20], Step [500/600], Loss: 0.2067023515701294\n",
            "Epoch [18/20], Step [600/600], Loss: 0.09801708906888962\n",
            "Epoch [19/20], Step [100/600], Loss: 0.23062163591384888\n",
            "Epoch [19/20], Step [200/600], Loss: 0.5139468908309937\n",
            "Epoch [19/20], Step [300/600], Loss: 0.3935936987400055\n",
            "Epoch [19/20], Step [400/600], Loss: 0.14084351062774658\n",
            "Epoch [19/20], Step [500/600], Loss: 0.11385490745306015\n",
            "Epoch [19/20], Step [600/600], Loss: 0.28281599283218384\n",
            "Epoch [20/20], Step [100/600], Loss: 0.10407690703868866\n",
            "Epoch [20/20], Step [200/600], Loss: 0.23179490864276886\n",
            "Epoch [20/20], Step [300/600], Loss: 0.11006929725408554\n",
            "Epoch [20/20], Step [400/600], Loss: 0.40968993306159973\n",
            "Epoch [20/20], Step [500/600], Loss: 0.1444244384765625\n",
            "Epoch [20/20], Step [600/600], Loss: 0.17294985055923462\n",
            "Accuracy of the model on the 10000 test images: 93.26% \n",
            "\n",
            "Training and evaluating Network #3\n",
            "Epoch [1/20], Step [100/600], Loss: 0.9705165028572083\n",
            "Epoch [1/20], Step [200/600], Loss: 0.49261078238487244\n",
            "Epoch [1/20], Step [300/600], Loss: 0.5285081267356873\n",
            "Epoch [1/20], Step [400/600], Loss: 0.40967899560928345\n",
            "Epoch [1/20], Step [500/600], Loss: 0.21692948043346405\n",
            "Epoch [1/20], Step [600/600], Loss: 0.4182487726211548\n",
            "Epoch [2/20], Step [100/600], Loss: 0.2729441821575165\n",
            "Epoch [2/20], Step [200/600], Loss: 0.45506182312965393\n",
            "Epoch [2/20], Step [300/600], Loss: 0.31950846314430237\n",
            "Epoch [2/20], Step [400/600], Loss: 0.22037555277347565\n",
            "Epoch [2/20], Step [500/600], Loss: 0.48178336024284363\n",
            "Epoch [2/20], Step [600/600], Loss: 0.25400587916374207\n",
            "Epoch [3/20], Step [100/600], Loss: 0.24337849020957947\n",
            "Epoch [3/20], Step [200/600], Loss: 0.2607538402080536\n",
            "Epoch [3/20], Step [300/600], Loss: 0.14985960721969604\n",
            "Epoch [3/20], Step [400/600], Loss: 0.40595322847366333\n",
            "Epoch [3/20], Step [500/600], Loss: 0.30828046798706055\n",
            "Epoch [3/20], Step [600/600], Loss: 0.30852290987968445\n",
            "Epoch [4/20], Step [100/600], Loss: 0.2622924745082855\n",
            "Epoch [4/20], Step [200/600], Loss: 0.14017239212989807\n",
            "Epoch [4/20], Step [300/600], Loss: 0.21826224029064178\n",
            "Epoch [4/20], Step [400/600], Loss: 0.25561007857322693\n",
            "Epoch [4/20], Step [500/600], Loss: 0.15155565738677979\n",
            "Epoch [4/20], Step [600/600], Loss: 0.14997047185897827\n",
            "Epoch [5/20], Step [100/600], Loss: 0.1853410005569458\n",
            "Epoch [5/20], Step [200/600], Loss: 0.25092706084251404\n",
            "Epoch [5/20], Step [300/600], Loss: 0.17688842117786407\n",
            "Epoch [5/20], Step [400/600], Loss: 0.3903941810131073\n",
            "Epoch [5/20], Step [500/600], Loss: 0.23799127340316772\n",
            "Epoch [5/20], Step [600/600], Loss: 0.23593325912952423\n",
            "Epoch [6/20], Step [100/600], Loss: 0.38209468126296997\n",
            "Epoch [6/20], Step [200/600], Loss: 0.3189083933830261\n",
            "Epoch [6/20], Step [300/600], Loss: 0.13893446326255798\n",
            "Epoch [6/20], Step [400/600], Loss: 0.32147452235221863\n",
            "Epoch [6/20], Step [500/600], Loss: 0.22322741150856018\n",
            "Epoch [6/20], Step [600/600], Loss: 0.1125442311167717\n",
            "Epoch [7/20], Step [100/600], Loss: 0.15785858035087585\n",
            "Epoch [7/20], Step [200/600], Loss: 0.13706880807876587\n",
            "Epoch [7/20], Step [300/600], Loss: 0.15192845463752747\n",
            "Epoch [7/20], Step [400/600], Loss: 0.31172892451286316\n",
            "Epoch [7/20], Step [500/600], Loss: 0.2481595277786255\n",
            "Epoch [7/20], Step [600/600], Loss: 0.15024641156196594\n",
            "Epoch [8/20], Step [100/600], Loss: 0.35693368315696716\n",
            "Epoch [8/20], Step [200/600], Loss: 0.313600093126297\n",
            "Epoch [8/20], Step [300/600], Loss: 0.08492725342512131\n",
            "Epoch [8/20], Step [400/600], Loss: 0.18697774410247803\n",
            "Epoch [8/20], Step [500/600], Loss: 0.2821374833583832\n",
            "Epoch [8/20], Step [600/600], Loss: 0.2525269687175751\n",
            "Epoch [9/20], Step [100/600], Loss: 0.31133362650871277\n",
            "Epoch [9/20], Step [200/600], Loss: 0.21596366167068481\n",
            "Epoch [9/20], Step [300/600], Loss: 0.27982527017593384\n",
            "Epoch [9/20], Step [400/600], Loss: 0.30736464262008667\n",
            "Epoch [9/20], Step [500/600], Loss: 0.42963844537734985\n",
            "Epoch [9/20], Step [600/600], Loss: 0.13291262090206146\n",
            "Epoch [10/20], Step [100/600], Loss: 0.1735265851020813\n",
            "Epoch [10/20], Step [200/600], Loss: 0.14849510788917542\n",
            "Epoch [10/20], Step [300/600], Loss: 0.22236374020576477\n",
            "Epoch [10/20], Step [400/600], Loss: 0.19088463485240936\n",
            "Epoch [10/20], Step [500/600], Loss: 0.23915612697601318\n",
            "Epoch [10/20], Step [600/600], Loss: 0.1678185909986496\n",
            "Epoch [11/20], Step [100/600], Loss: 0.25167736411094666\n",
            "Epoch [11/20], Step [200/600], Loss: 0.18717403709888458\n",
            "Epoch [11/20], Step [300/600], Loss: 0.1414782851934433\n",
            "Epoch [11/20], Step [400/600], Loss: 0.15413394570350647\n",
            "Epoch [11/20], Step [500/600], Loss: 0.12522616982460022\n",
            "Epoch [11/20], Step [600/600], Loss: 0.21156445145606995\n",
            "Epoch [12/20], Step [100/600], Loss: 0.13492967188358307\n",
            "Epoch [12/20], Step [200/600], Loss: 0.24777807295322418\n",
            "Epoch [12/20], Step [300/600], Loss: 0.05821150168776512\n",
            "Epoch [12/20], Step [400/600], Loss: 0.1891901046037674\n",
            "Epoch [12/20], Step [500/600], Loss: 0.4283694326877594\n",
            "Epoch [12/20], Step [600/600], Loss: 0.2158958613872528\n",
            "Epoch [13/20], Step [100/600], Loss: 0.31285330653190613\n",
            "Epoch [13/20], Step [200/600], Loss: 0.037617236375808716\n",
            "Epoch [13/20], Step [300/600], Loss: 0.07903192192316055\n",
            "Epoch [13/20], Step [400/600], Loss: 0.10554736107587814\n",
            "Epoch [13/20], Step [500/600], Loss: 0.15130899846553802\n",
            "Epoch [13/20], Step [600/600], Loss: 0.24990592896938324\n",
            "Epoch [14/20], Step [100/600], Loss: 0.092744380235672\n",
            "Epoch [14/20], Step [200/600], Loss: 0.17589063942432404\n",
            "Epoch [14/20], Step [300/600], Loss: 0.2749837338924408\n",
            "Epoch [14/20], Step [400/600], Loss: 0.1789548546075821\n",
            "Epoch [14/20], Step [500/600], Loss: 0.1379554718732834\n",
            "Epoch [14/20], Step [600/600], Loss: 0.12045099586248398\n",
            "Epoch [15/20], Step [100/600], Loss: 0.2131577730178833\n",
            "Epoch [15/20], Step [200/600], Loss: 0.2059372514486313\n",
            "Epoch [15/20], Step [300/600], Loss: 0.15489211678504944\n",
            "Epoch [15/20], Step [400/600], Loss: 0.3246450126171112\n",
            "Epoch [15/20], Step [500/600], Loss: 0.2478511929512024\n",
            "Epoch [15/20], Step [600/600], Loss: 0.27437058091163635\n",
            "Epoch [16/20], Step [100/600], Loss: 0.16774646937847137\n",
            "Epoch [16/20], Step [200/600], Loss: 0.1283888965845108\n",
            "Epoch [16/20], Step [300/600], Loss: 0.09891745448112488\n",
            "Epoch [16/20], Step [400/600], Loss: 0.3161725103855133\n",
            "Epoch [16/20], Step [500/600], Loss: 0.25632917881011963\n",
            "Epoch [16/20], Step [600/600], Loss: 0.26084059476852417\n",
            "Epoch [17/20], Step [100/600], Loss: 0.1182507798075676\n",
            "Epoch [17/20], Step [200/600], Loss: 0.13148659467697144\n",
            "Epoch [17/20], Step [300/600], Loss: 0.2476056069135666\n",
            "Epoch [17/20], Step [400/600], Loss: 0.29393327236175537\n",
            "Epoch [17/20], Step [500/600], Loss: 0.1602366864681244\n",
            "Epoch [17/20], Step [600/600], Loss: 0.24310913681983948\n",
            "Epoch [18/20], Step [100/600], Loss: 0.2896602153778076\n",
            "Epoch [18/20], Step [200/600], Loss: 0.26344627141952515\n",
            "Epoch [18/20], Step [300/600], Loss: 0.17470374703407288\n",
            "Epoch [18/20], Step [400/600], Loss: 0.3717913031578064\n",
            "Epoch [18/20], Step [500/600], Loss: 0.15115496516227722\n",
            "Epoch [18/20], Step [600/600], Loss: 0.09562455117702484\n",
            "Epoch [19/20], Step [100/600], Loss: 0.10329228639602661\n",
            "Epoch [19/20], Step [200/600], Loss: 0.4404617249965668\n",
            "Epoch [19/20], Step [300/600], Loss: 0.1126122921705246\n",
            "Epoch [19/20], Step [400/600], Loss: 0.16390188038349152\n",
            "Epoch [19/20], Step [500/600], Loss: 0.06467283517122269\n",
            "Epoch [19/20], Step [600/600], Loss: 0.16974681615829468\n",
            "Epoch [20/20], Step [100/600], Loss: 0.24999269843101501\n",
            "Epoch [20/20], Step [200/600], Loss: 0.1473040133714676\n",
            "Epoch [20/20], Step [300/600], Loss: 0.21125301718711853\n",
            "Epoch [20/20], Step [400/600], Loss: 0.132725328207016\n",
            "Epoch [20/20], Step [500/600], Loss: 0.26123306155204773\n",
            "Epoch [20/20], Step [600/600], Loss: 0.2867890000343323\n",
            "Accuracy of the model on the 10000 test images: 94.44% \n",
            "\n"
          ]
        }
      ]
    }
  ]
}