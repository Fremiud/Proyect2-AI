{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fremiud/Proyect2-AI/blob/main/Classification_AI_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIj99HJOQCJJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 100\n",
        "learning_rate = 0.01\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcXrsccCQGi6"
      },
      "outputs": [],
      "source": [
        "# Network #1\n",
        "class Network1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network1, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 20)\n",
        "        self.fc2 = nn.Linear(20, 50)\n",
        "        self.fc3 = nn.Linear(50, 20)\n",
        "        self.fc4 = nn.Linear(20, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Network #2\n",
        "class Network2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network2, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "        self.fc2 = nn.Linear(10, 20)\n",
        "        self.fc3 = nn.Linear(20, 30)\n",
        "        self.fc4 = nn.Linear(30, 20)\n",
        "        self.fc5 = nn.Linear(20, 10)\n",
        "        self.fc6 = nn.Linear(10, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = torch.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n",
        "\n",
        "# Network #3\n",
        "class Network3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network3, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "        self.fc2 = nn.Linear(10, 40)\n",
        "        self.fc3 = nn.Linear(40, 70)\n",
        "        self.fc4 = nn.Linear(70, 40)\n",
        "        self.fc5 = nn.Linear(40, 10)\n",
        "        self.fc6 = nn.Linear(10, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = torch.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU5EEKMTQH-R",
        "outputId": "85554df9-c435-47f6-9a91-2453c692cf1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 63824575.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 37961671.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25890287.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6326977.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-KAOmpjQKFR",
        "outputId": "41684d6b-47b3-4217-b067-975ffbef6f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training and evaluating Network #1\n",
            "Epoch [1/20], Step [100/600], Loss: 0.3895580768585205\n",
            "Epoch [1/20], Step [200/600], Loss: 0.299719899892807\n",
            "Epoch [1/20], Step [300/600], Loss: 0.3180945813655853\n",
            "Epoch [1/20], Step [400/600], Loss: 0.3885802924633026\n",
            "Epoch [1/20], Step [500/600], Loss: 0.2798721194267273\n",
            "Epoch [1/20], Step [600/600], Loss: 0.2044205516576767\n",
            "Epoch [2/20], Step [100/600], Loss: 0.19012580811977386\n",
            "Epoch [2/20], Step [200/600], Loss: 0.1148076131939888\n",
            "Epoch [2/20], Step [300/600], Loss: 0.16019898653030396\n",
            "Epoch [2/20], Step [400/600], Loss: 0.2581038773059845\n",
            "Epoch [2/20], Step [500/600], Loss: 0.20200014114379883\n",
            "Epoch [2/20], Step [600/600], Loss: 0.08083218336105347\n",
            "Epoch [3/20], Step [100/600], Loss: 0.13828784227371216\n",
            "Epoch [3/20], Step [200/600], Loss: 0.2714459002017975\n",
            "Epoch [3/20], Step [300/600], Loss: 0.2862204909324646\n",
            "Epoch [3/20], Step [400/600], Loss: 0.19216737151145935\n",
            "Epoch [3/20], Step [500/600], Loss: 0.15509654581546783\n",
            "Epoch [3/20], Step [600/600], Loss: 0.23629841208457947\n",
            "Epoch [4/20], Step [100/600], Loss: 0.32435500621795654\n",
            "Epoch [4/20], Step [200/600], Loss: 0.06595788896083832\n",
            "Epoch [4/20], Step [300/600], Loss: 0.04229232296347618\n",
            "Epoch [4/20], Step [400/600], Loss: 0.21234790980815887\n",
            "Epoch [4/20], Step [500/600], Loss: 0.09384353458881378\n",
            "Epoch [4/20], Step [600/600], Loss: 0.2040906548500061\n",
            "Epoch [5/20], Step [100/600], Loss: 0.0647740587592125\n",
            "Epoch [5/20], Step [200/600], Loss: 0.15811915695667267\n",
            "Epoch [5/20], Step [300/600], Loss: 0.10946507751941681\n",
            "Epoch [5/20], Step [400/600], Loss: 0.10244033485651016\n",
            "Epoch [5/20], Step [500/600], Loss: 0.15286314487457275\n",
            "Epoch [5/20], Step [600/600], Loss: 0.14015646278858185\n",
            "Epoch [6/20], Step [100/600], Loss: 0.10243353247642517\n",
            "Epoch [6/20], Step [200/600], Loss: 0.021956458687782288\n",
            "Epoch [6/20], Step [300/600], Loss: 0.09326302260160446\n",
            "Epoch [6/20], Step [400/600], Loss: 0.0735214501619339\n",
            "Epoch [6/20], Step [500/600], Loss: 0.2174791395664215\n",
            "Epoch [6/20], Step [600/600], Loss: 0.19758428633213043\n",
            "Epoch [7/20], Step [100/600], Loss: 0.15461698174476624\n",
            "Epoch [7/20], Step [200/600], Loss: 0.2008185237646103\n",
            "Epoch [7/20], Step [300/600], Loss: 0.1062886118888855\n",
            "Epoch [7/20], Step [400/600], Loss: 0.25734445452690125\n",
            "Epoch [7/20], Step [500/600], Loss: 0.08075285702943802\n",
            "Epoch [7/20], Step [600/600], Loss: 0.21186499297618866\n",
            "Epoch [8/20], Step [100/600], Loss: 0.20427262783050537\n",
            "Epoch [8/20], Step [200/600], Loss: 0.11554479598999023\n",
            "Epoch [8/20], Step [300/600], Loss: 0.12324859946966171\n",
            "Epoch [8/20], Step [400/600], Loss: 0.1351199448108673\n",
            "Epoch [8/20], Step [500/600], Loss: 0.03816203027963638\n",
            "Epoch [8/20], Step [600/600], Loss: 0.17771939933300018\n",
            "Epoch [9/20], Step [100/600], Loss: 0.1909084916114807\n",
            "Epoch [9/20], Step [200/600], Loss: 0.2898499369621277\n",
            "Epoch [9/20], Step [300/600], Loss: 0.1986604928970337\n",
            "Epoch [9/20], Step [400/600], Loss: 0.11335206776857376\n",
            "Epoch [9/20], Step [500/600], Loss: 0.3700823187828064\n",
            "Epoch [9/20], Step [600/600], Loss: 0.18732552230358124\n",
            "Epoch [10/20], Step [100/600], Loss: 0.026607435196638107\n",
            "Epoch [10/20], Step [200/600], Loss: 0.11676495522260666\n",
            "Epoch [10/20], Step [300/600], Loss: 0.09129804372787476\n",
            "Epoch [10/20], Step [400/600], Loss: 0.12672406435012817\n",
            "Epoch [10/20], Step [500/600], Loss: 0.2194785326719284\n",
            "Epoch [10/20], Step [600/600], Loss: 0.09536300599575043\n",
            "Epoch [11/20], Step [100/600], Loss: 0.0882285088300705\n",
            "Epoch [11/20], Step [200/600], Loss: 0.1892046481370926\n",
            "Epoch [11/20], Step [300/600], Loss: 0.2548762261867523\n",
            "Epoch [11/20], Step [400/600], Loss: 0.1265120655298233\n",
            "Epoch [11/20], Step [500/600], Loss: 0.11959345638751984\n",
            "Epoch [11/20], Step [600/600], Loss: 0.1342933475971222\n",
            "Epoch [12/20], Step [100/600], Loss: 0.11986374855041504\n",
            "Epoch [12/20], Step [200/600], Loss: 0.09146267175674438\n",
            "Epoch [12/20], Step [300/600], Loss: 0.03761326149106026\n",
            "Epoch [12/20], Step [400/600], Loss: 0.17116624116897583\n",
            "Epoch [12/20], Step [500/600], Loss: 0.278993159532547\n",
            "Epoch [12/20], Step [600/600], Loss: 0.07645385712385178\n",
            "Epoch [13/20], Step [100/600], Loss: 0.1867298185825348\n",
            "Epoch [13/20], Step [200/600], Loss: 0.05770318955183029\n",
            "Epoch [13/20], Step [300/600], Loss: 0.13240860402584076\n",
            "Epoch [13/20], Step [400/600], Loss: 0.03730422630906105\n",
            "Epoch [13/20], Step [500/600], Loss: 0.12856291234493256\n",
            "Epoch [13/20], Step [600/600], Loss: 0.1330750733613968\n",
            "Epoch [14/20], Step [100/600], Loss: 0.05860264599323273\n",
            "Epoch [14/20], Step [200/600], Loss: 0.06970100849866867\n",
            "Epoch [14/20], Step [300/600], Loss: 0.08888223767280579\n",
            "Epoch [14/20], Step [400/600], Loss: 0.0943078100681305\n",
            "Epoch [14/20], Step [500/600], Loss: 0.07696937769651413\n",
            "Epoch [14/20], Step [600/600], Loss: 0.1619756817817688\n",
            "Epoch [15/20], Step [100/600], Loss: 0.1436275988817215\n",
            "Epoch [15/20], Step [200/600], Loss: 0.15830931067466736\n",
            "Epoch [15/20], Step [300/600], Loss: 0.1124831885099411\n",
            "Epoch [15/20], Step [400/600], Loss: 0.049630023539066315\n",
            "Epoch [15/20], Step [500/600], Loss: 0.2534789443016052\n",
            "Epoch [15/20], Step [600/600], Loss: 0.18191537261009216\n",
            "Epoch [16/20], Step [100/600], Loss: 0.10196247696876526\n",
            "Epoch [16/20], Step [200/600], Loss: 0.09559997916221619\n",
            "Epoch [16/20], Step [300/600], Loss: 0.039249200373888016\n",
            "Epoch [16/20], Step [400/600], Loss: 0.14901527762413025\n",
            "Epoch [16/20], Step [500/600], Loss: 0.052840620279312134\n",
            "Epoch [16/20], Step [600/600], Loss: 0.11322779953479767\n",
            "Epoch [17/20], Step [100/600], Loss: 0.18613959848880768\n",
            "Epoch [17/20], Step [200/600], Loss: 0.10845821350812912\n",
            "Epoch [17/20], Step [300/600], Loss: 0.04075949639081955\n",
            "Epoch [17/20], Step [400/600], Loss: 0.05665881931781769\n",
            "Epoch [17/20], Step [500/600], Loss: 0.09974391758441925\n",
            "Epoch [17/20], Step [600/600], Loss: 0.26688581705093384\n",
            "Epoch [18/20], Step [100/600], Loss: 0.032956257462501526\n",
            "Epoch [18/20], Step [200/600], Loss: 0.25346997380256653\n",
            "Epoch [18/20], Step [300/600], Loss: 0.02543284371495247\n",
            "Epoch [18/20], Step [400/600], Loss: 0.07406692206859589\n",
            "Epoch [18/20], Step [500/600], Loss: 0.03562058508396149\n",
            "Epoch [18/20], Step [600/600], Loss: 0.1341744065284729\n",
            "Epoch [19/20], Step [100/600], Loss: 0.0651935264468193\n",
            "Epoch [19/20], Step [200/600], Loss: 0.12018194049596786\n",
            "Epoch [19/20], Step [300/600], Loss: 0.24777580797672272\n",
            "Epoch [19/20], Step [400/600], Loss: 0.0774078443646431\n",
            "Epoch [19/20], Step [500/600], Loss: 0.18805795907974243\n",
            "Epoch [19/20], Step [600/600], Loss: 0.21405766904354095\n",
            "Epoch [20/20], Step [100/600], Loss: 0.09661222249269485\n",
            "Epoch [20/20], Step [200/600], Loss: 0.128357395529747\n",
            "Epoch [20/20], Step [300/600], Loss: 0.2242930382490158\n",
            "Epoch [20/20], Step [400/600], Loss: 0.15867389738559723\n",
            "Epoch [20/20], Step [500/600], Loss: 0.037100840359926224\n",
            "Epoch [20/20], Step [600/600], Loss: 0.13170696794986725\n",
            "Accuracy of the model on the 10000 test images: 95.93% \n",
            "\n",
            "Training and evaluating Network #2\n",
            "Epoch [1/20], Step [100/600], Loss: 0.8004747629165649\n",
            "Epoch [1/20], Step [200/600], Loss: 0.8019554615020752\n",
            "Epoch [1/20], Step [300/600], Loss: 0.5779220461845398\n",
            "Epoch [1/20], Step [400/600], Loss: 0.36698803305625916\n",
            "Epoch [1/20], Step [500/600], Loss: 0.3226906955242157\n",
            "Epoch [1/20], Step [600/600], Loss: 0.631803035736084\n",
            "Epoch [2/20], Step [100/600], Loss: 0.39582642912864685\n",
            "Epoch [2/20], Step [200/600], Loss: 0.3762702941894531\n",
            "Epoch [2/20], Step [300/600], Loss: 0.2509796619415283\n",
            "Epoch [2/20], Step [400/600], Loss: 0.35243362188339233\n",
            "Epoch [2/20], Step [500/600], Loss: 0.4495704174041748\n",
            "Epoch [2/20], Step [600/600], Loss: 0.3674185574054718\n",
            "Epoch [3/20], Step [100/600], Loss: 0.4972066581249237\n",
            "Epoch [3/20], Step [200/600], Loss: 0.4125278890132904\n",
            "Epoch [3/20], Step [300/600], Loss: 0.20417560636997223\n",
            "Epoch [3/20], Step [400/600], Loss: 0.29757189750671387\n",
            "Epoch [3/20], Step [500/600], Loss: 0.2847803831100464\n",
            "Epoch [3/20], Step [600/600], Loss: 0.3827472925186157\n",
            "Epoch [4/20], Step [100/600], Loss: 0.18408402800559998\n",
            "Epoch [4/20], Step [200/600], Loss: 0.2900788187980652\n",
            "Epoch [4/20], Step [300/600], Loss: 0.3258155584335327\n",
            "Epoch [4/20], Step [400/600], Loss: 0.3898831903934479\n",
            "Epoch [4/20], Step [500/600], Loss: 0.38520774245262146\n",
            "Epoch [4/20], Step [600/600], Loss: 0.39088404178619385\n",
            "Epoch [5/20], Step [100/600], Loss: 0.39959344267845154\n",
            "Epoch [5/20], Step [200/600], Loss: 0.44207465648651123\n",
            "Epoch [5/20], Step [300/600], Loss: 0.29997652769088745\n",
            "Epoch [5/20], Step [400/600], Loss: 0.4725532531738281\n",
            "Epoch [5/20], Step [500/600], Loss: 0.494272381067276\n",
            "Epoch [5/20], Step [600/600], Loss: 0.32121220231056213\n",
            "Epoch [6/20], Step [100/600], Loss: 0.17878396809101105\n",
            "Epoch [6/20], Step [200/600], Loss: 0.2900277376174927\n",
            "Epoch [6/20], Step [300/600], Loss: 0.25260135531425476\n",
            "Epoch [6/20], Step [400/600], Loss: 0.1906658411026001\n",
            "Epoch [6/20], Step [500/600], Loss: 0.37993499636650085\n",
            "Epoch [6/20], Step [600/600], Loss: 0.3311411738395691\n",
            "Epoch [7/20], Step [100/600], Loss: 0.31147289276123047\n",
            "Epoch [7/20], Step [200/600], Loss: 0.3378523290157318\n",
            "Epoch [7/20], Step [300/600], Loss: 0.46380600333213806\n",
            "Epoch [7/20], Step [400/600], Loss: 0.16817894577980042\n",
            "Epoch [7/20], Step [500/600], Loss: 0.318488210439682\n",
            "Epoch [7/20], Step [600/600], Loss: 0.2850058376789093\n",
            "Epoch [8/20], Step [100/600], Loss: 0.37013179063796997\n",
            "Epoch [8/20], Step [200/600], Loss: 0.3001042604446411\n",
            "Epoch [8/20], Step [300/600], Loss: 0.27492114901542664\n",
            "Epoch [8/20], Step [400/600], Loss: 0.349059134721756\n",
            "Epoch [8/20], Step [500/600], Loss: 0.18081986904144287\n",
            "Epoch [8/20], Step [600/600], Loss: 0.3615507185459137\n",
            "Epoch [9/20], Step [100/600], Loss: 0.16714288294315338\n",
            "Epoch [9/20], Step [200/600], Loss: 0.20774152874946594\n",
            "Epoch [9/20], Step [300/600], Loss: 0.2773164212703705\n",
            "Epoch [9/20], Step [400/600], Loss: 0.1639230102300644\n",
            "Epoch [9/20], Step [500/600], Loss: 0.17992617189884186\n",
            "Epoch [9/20], Step [600/600], Loss: 0.19914212822914124\n",
            "Epoch [10/20], Step [100/600], Loss: 0.169420525431633\n",
            "Epoch [10/20], Step [200/600], Loss: 0.22698333859443665\n",
            "Epoch [10/20], Step [300/600], Loss: 0.2554079592227936\n",
            "Epoch [10/20], Step [400/600], Loss: 0.12795929610729218\n",
            "Epoch [10/20], Step [500/600], Loss: 0.34559357166290283\n",
            "Epoch [10/20], Step [600/600], Loss: 0.20924758911132812\n",
            "Epoch [11/20], Step [100/600], Loss: 0.3297979235649109\n",
            "Epoch [11/20], Step [200/600], Loss: 0.19851355254650116\n",
            "Epoch [11/20], Step [300/600], Loss: 0.2720719575881958\n",
            "Epoch [11/20], Step [400/600], Loss: 0.11888180673122406\n",
            "Epoch [11/20], Step [500/600], Loss: 0.4298741817474365\n",
            "Epoch [11/20], Step [600/600], Loss: 0.22061727941036224\n",
            "Epoch [12/20], Step [100/600], Loss: 0.33664295077323914\n",
            "Epoch [12/20], Step [200/600], Loss: 0.2209329456090927\n",
            "Epoch [12/20], Step [300/600], Loss: 0.27506375312805176\n",
            "Epoch [12/20], Step [400/600], Loss: 0.22843390703201294\n",
            "Epoch [12/20], Step [500/600], Loss: 0.20916661620140076\n",
            "Epoch [12/20], Step [600/600], Loss: 0.3934441804885864\n",
            "Epoch [13/20], Step [100/600], Loss: 0.30139991641044617\n",
            "Epoch [13/20], Step [200/600], Loss: 0.17205844819545746\n",
            "Epoch [13/20], Step [300/600], Loss: 0.13554121553897858\n",
            "Epoch [13/20], Step [400/600], Loss: 0.20760250091552734\n",
            "Epoch [13/20], Step [500/600], Loss: 0.19733655452728271\n",
            "Epoch [13/20], Step [600/600], Loss: 0.37932059168815613\n",
            "Epoch [14/20], Step [100/600], Loss: 0.20955045521259308\n",
            "Epoch [14/20], Step [200/600], Loss: 0.22812671959400177\n",
            "Epoch [14/20], Step [300/600], Loss: 0.15179620683193207\n",
            "Epoch [14/20], Step [400/600], Loss: 0.30903178453445435\n",
            "Epoch [14/20], Step [500/600], Loss: 0.3099299967288971\n",
            "Epoch [14/20], Step [600/600], Loss: 0.12719221413135529\n",
            "Epoch [15/20], Step [100/600], Loss: 0.33476024866104126\n",
            "Epoch [15/20], Step [200/600], Loss: 0.1426805853843689\n",
            "Epoch [15/20], Step [300/600], Loss: 0.5005907416343689\n",
            "Epoch [15/20], Step [400/600], Loss: 0.2231823205947876\n",
            "Epoch [15/20], Step [500/600], Loss: 0.21727406978607178\n",
            "Epoch [15/20], Step [600/600], Loss: 0.2003602534532547\n",
            "Epoch [16/20], Step [100/600], Loss: 0.18742668628692627\n",
            "Epoch [16/20], Step [200/600], Loss: 0.2550632059574127\n",
            "Epoch [16/20], Step [300/600], Loss: 0.22833837568759918\n",
            "Epoch [16/20], Step [400/600], Loss: 0.4838629961013794\n",
            "Epoch [16/20], Step [500/600], Loss: 0.2870943248271942\n",
            "Epoch [16/20], Step [600/600], Loss: 0.523968517780304\n",
            "Epoch [17/20], Step [100/600], Loss: 0.19731582701206207\n",
            "Epoch [17/20], Step [200/600], Loss: 0.1626644730567932\n",
            "Epoch [17/20], Step [300/600], Loss: 0.12143813818693161\n",
            "Epoch [17/20], Step [400/600], Loss: 0.1866634339094162\n",
            "Epoch [17/20], Step [500/600], Loss: 0.17592613399028778\n",
            "Epoch [17/20], Step [600/600], Loss: 0.21439093351364136\n",
            "Epoch [18/20], Step [100/600], Loss: 0.1347557008266449\n",
            "Epoch [18/20], Step [200/600], Loss: 0.22568002343177795\n",
            "Epoch [18/20], Step [300/600], Loss: 0.3161625564098358\n",
            "Epoch [18/20], Step [400/600], Loss: 0.24049842357635498\n",
            "Epoch [18/20], Step [500/600], Loss: 0.34739169478416443\n",
            "Epoch [18/20], Step [600/600], Loss: 0.21822910010814667\n",
            "Epoch [19/20], Step [100/600], Loss: 0.2459283471107483\n",
            "Epoch [19/20], Step [200/600], Loss: 0.0747312605381012\n",
            "Epoch [19/20], Step [300/600], Loss: 0.11063633859157562\n",
            "Epoch [19/20], Step [400/600], Loss: 0.4005908668041229\n",
            "Epoch [19/20], Step [500/600], Loss: 0.2394140064716339\n",
            "Epoch [19/20], Step [600/600], Loss: 0.3151766061782837\n",
            "Epoch [20/20], Step [100/600], Loss: 0.11829019337892532\n",
            "Epoch [20/20], Step [200/600], Loss: 0.3255939483642578\n",
            "Epoch [20/20], Step [300/600], Loss: 0.21121905744075775\n",
            "Epoch [20/20], Step [400/600], Loss: 0.22218281030654907\n",
            "Epoch [20/20], Step [500/600], Loss: 0.24250181019306183\n",
            "Epoch [20/20], Step [600/600], Loss: 0.23078912496566772\n",
            "Accuracy of the model on the 10000 test images: 92.6% \n",
            "\n",
            "Training and evaluating Network #3\n",
            "Epoch [1/20], Step [100/600], Loss: 0.5922231078147888\n",
            "Epoch [1/20], Step [200/600], Loss: 0.4844278395175934\n",
            "Epoch [1/20], Step [300/600], Loss: 0.346423864364624\n",
            "Epoch [1/20], Step [400/600], Loss: 0.2788856625556946\n",
            "Epoch [1/20], Step [500/600], Loss: 0.3170258700847626\n",
            "Epoch [1/20], Step [600/600], Loss: 0.4891222417354584\n",
            "Epoch [2/20], Step [100/600], Loss: 0.49812138080596924\n",
            "Epoch [2/20], Step [200/600], Loss: 0.24485202133655548\n",
            "Epoch [2/20], Step [300/600], Loss: 0.234293594956398\n",
            "Epoch [2/20], Step [400/600], Loss: 0.16367490589618683\n",
            "Epoch [2/20], Step [500/600], Loss: 0.303011953830719\n",
            "Epoch [2/20], Step [600/600], Loss: 0.3226696252822876\n",
            "Epoch [3/20], Step [100/600], Loss: 0.27014443278312683\n",
            "Epoch [3/20], Step [200/600], Loss: 0.32771480083465576\n",
            "Epoch [3/20], Step [300/600], Loss: 0.4985179603099823\n",
            "Epoch [3/20], Step [400/600], Loss: 0.3205324113368988\n",
            "Epoch [3/20], Step [500/600], Loss: 0.24526019394397736\n",
            "Epoch [3/20], Step [600/600], Loss: 0.217664435505867\n",
            "Epoch [4/20], Step [100/600], Loss: 0.2271827757358551\n",
            "Epoch [4/20], Step [200/600], Loss: 0.26877331733703613\n",
            "Epoch [4/20], Step [300/600], Loss: 0.2293679118156433\n",
            "Epoch [4/20], Step [400/600], Loss: 0.2452300488948822\n",
            "Epoch [4/20], Step [500/600], Loss: 0.32230421900749207\n",
            "Epoch [4/20], Step [600/600], Loss: 0.20440348982810974\n",
            "Epoch [5/20], Step [100/600], Loss: 0.15470439195632935\n",
            "Epoch [5/20], Step [200/600], Loss: 0.29465728998184204\n",
            "Epoch [5/20], Step [300/600], Loss: 0.24788092076778412\n",
            "Epoch [5/20], Step [400/600], Loss: 0.26583027839660645\n",
            "Epoch [5/20], Step [500/600], Loss: 0.15760056674480438\n",
            "Epoch [5/20], Step [600/600], Loss: 0.2422606647014618\n",
            "Epoch [6/20], Step [100/600], Loss: 0.1986190378665924\n",
            "Epoch [6/20], Step [200/600], Loss: 0.25867941975593567\n",
            "Epoch [6/20], Step [300/600], Loss: 0.32892611622810364\n",
            "Epoch [6/20], Step [400/600], Loss: 0.430708110332489\n",
            "Epoch [6/20], Step [500/600], Loss: 0.2621561288833618\n",
            "Epoch [6/20], Step [600/600], Loss: 0.2628037631511688\n",
            "Epoch [7/20], Step [100/600], Loss: 0.2626115083694458\n",
            "Epoch [7/20], Step [200/600], Loss: 0.21603897213935852\n",
            "Epoch [7/20], Step [300/600], Loss: 0.19327886402606964\n",
            "Epoch [7/20], Step [400/600], Loss: 0.2655651867389679\n",
            "Epoch [7/20], Step [500/600], Loss: 0.09139451384544373\n",
            "Epoch [7/20], Step [600/600], Loss: 0.21409420669078827\n",
            "Epoch [8/20], Step [100/600], Loss: 0.3202570080757141\n",
            "Epoch [8/20], Step [200/600], Loss: 0.20446717739105225\n",
            "Epoch [8/20], Step [300/600], Loss: 0.30733832716941833\n",
            "Epoch [8/20], Step [400/600], Loss: 0.23455113172531128\n",
            "Epoch [8/20], Step [500/600], Loss: 0.14175331592559814\n",
            "Epoch [8/20], Step [600/600], Loss: 0.21673808991909027\n",
            "Epoch [9/20], Step [100/600], Loss: 0.15397614240646362\n",
            "Epoch [9/20], Step [200/600], Loss: 0.35667479038238525\n",
            "Epoch [9/20], Step [300/600], Loss: 0.12968744337558746\n",
            "Epoch [9/20], Step [400/600], Loss: 0.24620839953422546\n",
            "Epoch [9/20], Step [500/600], Loss: 0.4594382047653198\n",
            "Epoch [9/20], Step [600/600], Loss: 0.21007968485355377\n",
            "Epoch [10/20], Step [100/600], Loss: 0.18654310703277588\n",
            "Epoch [10/20], Step [200/600], Loss: 0.1673983782529831\n",
            "Epoch [10/20], Step [300/600], Loss: 0.2885914444923401\n",
            "Epoch [10/20], Step [400/600], Loss: 0.1523248702287674\n",
            "Epoch [10/20], Step [500/600], Loss: 0.15042385458946228\n",
            "Epoch [10/20], Step [600/600], Loss: 0.2858848571777344\n",
            "Epoch [11/20], Step [100/600], Loss: 0.15052643418312073\n",
            "Epoch [11/20], Step [200/600], Loss: 0.24560527503490448\n",
            "Epoch [11/20], Step [300/600], Loss: 0.23347492516040802\n",
            "Epoch [11/20], Step [400/600], Loss: 0.3867829442024231\n",
            "Epoch [11/20], Step [500/600], Loss: 0.10995443165302277\n",
            "Epoch [11/20], Step [600/600], Loss: 0.23535455763339996\n",
            "Epoch [12/20], Step [100/600], Loss: 0.2977612614631653\n",
            "Epoch [12/20], Step [200/600], Loss: 0.2210174798965454\n",
            "Epoch [12/20], Step [300/600], Loss: 0.14176300168037415\n",
            "Epoch [12/20], Step [400/600], Loss: 0.378143310546875\n",
            "Epoch [12/20], Step [500/600], Loss: 0.196609765291214\n",
            "Epoch [12/20], Step [600/600], Loss: 0.15208810567855835\n",
            "Epoch [13/20], Step [100/600], Loss: 0.27327725291252136\n",
            "Epoch [13/20], Step [200/600], Loss: 0.4620102345943451\n",
            "Epoch [13/20], Step [300/600], Loss: 0.29684212803840637\n",
            "Epoch [13/20], Step [400/600], Loss: 0.23913411796092987\n",
            "Epoch [13/20], Step [500/600], Loss: 0.27307969331741333\n",
            "Epoch [13/20], Step [600/600], Loss: 0.15369632840156555\n",
            "Epoch [14/20], Step [100/600], Loss: 0.14783506095409393\n",
            "Epoch [14/20], Step [200/600], Loss: 0.2460113912820816\n",
            "Epoch [14/20], Step [300/600], Loss: 0.08119965344667435\n",
            "Epoch [14/20], Step [400/600], Loss: 0.30288031697273254\n",
            "Epoch [14/20], Step [500/600], Loss: 0.17385651171207428\n",
            "Epoch [14/20], Step [600/600], Loss: 0.2174084335565567\n",
            "Epoch [15/20], Step [100/600], Loss: 0.28721240162849426\n",
            "Epoch [15/20], Step [200/600], Loss: 0.2350974678993225\n",
            "Epoch [15/20], Step [300/600], Loss: 0.2929948568344116\n",
            "Epoch [15/20], Step [400/600], Loss: 0.20210471749305725\n",
            "Epoch [15/20], Step [500/600], Loss: 0.1567291021347046\n",
            "Epoch [15/20], Step [600/600], Loss: 0.17219345271587372\n",
            "Epoch [16/20], Step [100/600], Loss: 0.30487221479415894\n",
            "Epoch [16/20], Step [200/600], Loss: 0.21041081845760345\n",
            "Epoch [16/20], Step [300/600], Loss: 0.15844778716564178\n",
            "Epoch [16/20], Step [400/600], Loss: 0.06739817559719086\n",
            "Epoch [16/20], Step [500/600], Loss: 0.2358522266149521\n",
            "Epoch [16/20], Step [600/600], Loss: 0.210149884223938\n",
            "Epoch [17/20], Step [100/600], Loss: 0.21753087639808655\n",
            "Epoch [17/20], Step [200/600], Loss: 0.17430026829242706\n",
            "Epoch [17/20], Step [300/600], Loss: 0.13636253774166107\n",
            "Epoch [17/20], Step [400/600], Loss: 0.2704320251941681\n",
            "Epoch [17/20], Step [500/600], Loss: 0.2653335630893707\n",
            "Epoch [17/20], Step [600/600], Loss: 0.10455895215272903\n",
            "Epoch [18/20], Step [100/600], Loss: 0.2272874265909195\n",
            "Epoch [18/20], Step [200/600], Loss: 0.11417725682258606\n",
            "Epoch [18/20], Step [300/600], Loss: 0.15428104996681213\n",
            "Epoch [18/20], Step [400/600], Loss: 0.147441565990448\n",
            "Epoch [18/20], Step [500/600], Loss: 0.300605833530426\n",
            "Epoch [18/20], Step [600/600], Loss: 0.20826798677444458\n",
            "Epoch [19/20], Step [100/600], Loss: 0.1826447695493698\n",
            "Epoch [19/20], Step [200/600], Loss: 0.27542537450790405\n",
            "Epoch [19/20], Step [300/600], Loss: 0.3475920557975769\n",
            "Epoch [19/20], Step [400/600], Loss: 0.2569161355495453\n",
            "Epoch [19/20], Step [500/600], Loss: 0.21240895986557007\n",
            "Epoch [19/20], Step [600/600], Loss: 0.10103430598974228\n",
            "Epoch [20/20], Step [100/600], Loss: 0.1699325144290924\n",
            "Epoch [20/20], Step [200/600], Loss: 0.30794650316238403\n",
            "Epoch [20/20], Step [300/600], Loss: 0.2216898798942566\n",
            "Epoch [20/20], Step [400/600], Loss: 0.15299662947654724\n",
            "Epoch [20/20], Step [500/600], Loss: 0.2491159439086914\n",
            "Epoch [20/20], Step [600/600], Loss: 0.21732491254806519\n",
            "Accuracy of the model on the 10000 test images: 94.21% \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def train_and_evaluate(model, train_loader, test_loader):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.view(-1, 28*28)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item()}')\n",
        "\n",
        "    # Evaluation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.view(-1, 28*28)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f'Accuracy of the model on the 10000 test images: {100 * correct / total}% \\n')\n",
        "\n",
        "# Train and evaluate Network #1\n",
        "print(\"Training and evaluating Network #1\")\n",
        "model1 = Network1()\n",
        "train_and_evaluate(model1, train_loader, test_loader)\n",
        "\n",
        "# Train and evaluate Network #2\n",
        "print(\"Training and evaluating Network #2\")\n",
        "model2 = Network2()\n",
        "train_and_evaluate(model2, train_loader, test_loader)\n",
        "\n",
        "# Train and evaluate Network #3\n",
        "print(\"Training and evaluating Network #3\")\n",
        "model3 = Network3()\n",
        "train_and_evaluate(model3, train_loader, test_loader)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHSY/FfNT9c2lttF3GAxfo",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}