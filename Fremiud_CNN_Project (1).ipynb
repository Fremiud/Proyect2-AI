{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wQZTH4KHHim4"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "FREMIUD OTERO CORDERO\n",
        "802-19-4359"
      ],
      "metadata": {
        "id": "7Tfw5IV7HYrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set-Up"
      ],
      "metadata": {
        "id": "wQZTH4KHHim4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ydl31FjF0Gt",
        "outputId": "f6ef2681-0a24-4e1a-d844-fff25a4ea2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDv6b-gddc6o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchinfo import summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code segment sets up the device for PyTorch operations and prepares the MNIST dataset for training and testing. It first checks if a CUDA-enabled GPU is available and assigns the device variable accordingly. If CUDA is not available, it checks for the Multi-Process Service (MPS) backend and assigns the device variable to \"mps\" if available, or \"cpu\" if neither CUDA nor MPS is available. The selected device is then printed. "
      ],
      "metadata": {
        "id": "9HSpFyMpLpQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "torch.device(device)\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "w1anQbDDF3FB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b265f68a-6e5e-41d5-97a4-6dd0c5566180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code further defines a transformation pipeline for data preprocessing and sets the batch size. It creates data loaders for both the training and testing datasets, enabling efficient loading of data in batches for training and evaluation purposes."
      ],
      "metadata": {
        "id": "zjNcVmoSLnvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "IRybPFcXdqCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Convolutional Neural Networks:"
      ],
      "metadata": {
        "id": "q1HIJFWieBcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network #1: 4 layers\n",
        "* Layer 1 – convolution with 16 filters, each filter 5x5 with same padding\n",
        "* Layer 2 – ReLU activation\n",
        "* Layer 3 – Flatten layer\n",
        "* Layer 4 – fully connected layer with 10 neurons as output (using cross entropy\n",
        "loss does the softmax)"
      ],
      "metadata": {
        "id": "dduUCSZCMPrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 5, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(16 * 28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "afT89EmTeA1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network #2: 8- layer network\n",
        "* Layer 1 – convolution with 6 filters , each filter 5x5 with same padding\n",
        "* Layer 2 – ReLU activation\n",
        "* Layer 3 – convolution with 16 filters , each filter 5x5 with same padding\n",
        "* Layer 4 – ReLU activation\n",
        "* Layer 5 – flatten layer\n",
        "* Leyer 6 – fully connected layer with 84 neurons as ouput\n",
        "* Layer 7 – ReLU activation\n",
        "* Layer 8 - fully connected layer with 10 neurons as output (using cross entropy\n",
        "loss does the softmax)"
      ],
      "metadata": {
        "id": "5QCu124DMlFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, padding='same')\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, padding='same')\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(16 * 28 * 28, 84)\n",
        "        self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "OOTAZJWPeKwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network #3: 14- layer network\n",
        "* Layer 1 – convolution with 6 filters , each filter 5x5 with same padding\n",
        "* Layer 2 – batch normalization for 6 filters\n",
        "* Layer 3 – ReLU activation\n",
        "* Layer 4 – Max pooling of size 2 (to halve de image)\n",
        "* Layer 5 – convolution with 16 filters , each filter 5x5 with same padding\n",
        "* Layer 6 – batch normalization for 16 filters\n",
        "* Layer 7 – ReLU activation\n",
        "* Layer 8 – Max pooling of size 2 (to halve de image)\n",
        "* Layer 9 – flatten layer\n",
        "* Leyer 10 – fully connected layer with 120 neurons as ouput\n",
        "* Layer 11 – ReLU activation\n",
        "* Leyer 12 – fully connected layer with 84 neurons as ouput\n",
        "* Layer 13 – ReLU activation\n",
        "* Layer 14 - fully connected layer with 10 neurons as output (using cross entropy\n",
        "loss does the softmax)"
      ],
      "metadata": {
        "id": "UNK-If39MwTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, padding='same')\n",
        "        self.bn1 = nn.BatchNorm2d(6)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.max_pool = torch.nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, padding='same')\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        \n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)        \n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "btjLJWrseNjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus Network: 16-layer network\n",
        "\n",
        "* Layer 1 – Convolutional layer with 1 input channel, 6 output channels, a kernel size of 3x3, and padding of 2.\n",
        "* Layer 2 – Batch normalization applied to the outputs of the previous convolutional layer.\n",
        "* Layer 3 – ReLU activation function.\n",
        "* Layer 4 – Max pooling of size 2x2.\n",
        "* Layer 5 – Convolutional layer with 6 input channels, 16 output channels, a kernel size of 3x3, and padding of 2.\n",
        "* Layer 6 – Batch normalization applied to the outputs of the previous convolutional layer.\n",
        "* Layer 7 – ReLU activation function.\n",
        "* Layer 8 – Max pooling of size 2x2.\n",
        "* Layer 9 – Flatten layer to transform the data into a 1-dimensional tensor.\n",
        "* Layer 10 – Fully connected layer with 16 * 8 * 8 = 1024 input neurons and 256 output neurons.\n",
        "* Layer 11 – ReLU activation function.\n",
        "* Layer 12 – Dropout layer with a specified dropout rate.\n",
        "* Layer 13 – Fully connected layer with 256 input neurons and 64 output neurons.\n",
        "* Layer 14 – ReLU activation function.\n",
        "* Layer 15 – Dropout layer with a specified dropout rate.\n",
        "* Layer 16 – Fully connected layer with 64 input neurons and 10 output neurons.\n",
        "\n"
      ],
      "metadata": {
        "id": "RisXLnGbNUm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bonus(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.2):\n",
        "        super(Bonus, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pool(x)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "kkNRKIJ8HqwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define evaluate and train functions:"
      ],
      "metadata": {
        "id": "c9QlHGimdtpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train function trains a neural network model by iterating over the data batches, performing forward and backward passes, updating the model parameters, and calculating the running loss and accuracy. It returns the average loss, accuracy, and a list of individual losses for each batch."
      ],
      "metadata": {
        "id": "fXPSOsMLP6BM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, dataloader, criterion, optimizer, device):\n",
        "    net.train()\n",
        "    correct = 0\n",
        "    running_loss = 0.0\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    loss_list=[]\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            loss, current = loss.item(), i * len(inputs)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "    accuracy = 100 * correct / size\n",
        "    return running_loss / num_batches,accuracy,loss_list\n"
      ],
      "metadata": {
        "id": "8VMfjSFkdsNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluate function evaluates the trained model on a separate dataset by iterating over the data batches, calculating predictions, and calculating the running loss and accuracy. It returns the average loss and accuracy."
      ],
      "metadata": {
        "id": "oV_NrRwEP4k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(net, dataloader, criterion, device):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    running_loss = 0.0\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    accuracy = 100 * correct / size\n",
        "    return running_loss / num_batches, accuracy\n"
      ],
      "metadata": {
        "id": "BiivYi3bdsvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train_test_loop function combines the training and evaluation process in a loop for a specified number of epochs. It prints the training accuracy and loss for each epoch and evaluates the model on a test dataset. It returns a list of individual losses for each batch during training."
      ],
      "metadata": {
        "id": "P-jW7EFsP3Vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train_test_loop(net,epochs,lr,criterion,optimizer):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net.to(device)\n",
        "\n",
        "    start_time = time.time()\n",
        "         \n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch: \", epoch+1)\n",
        "        print(\"--------------\") \n",
        "        train_loss,train_accuracy,loss_list = train(net, trainloader, criterion, optimizer, device)\n",
        "        print(f\"Train Error: \\n Accuracy: {(train_accuracy):>0.2f}%, Avg loss: {train_loss:>8f} \\n\")\n",
        "    \n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    val_loss, test_accuracy = evaluate(net, testloader, criterion, device)\n",
        "    print(f\"Test Accuracy: {(test_accuracy):>0.2f}%, Avg Test loss: {val_loss:>8f}, Training Time: {elapsed_time/60:.2f} minutes \\n\")\n",
        "    return loss_list\n"
      ],
      "metadata": {
        "id": "TpPVZ3BTmuS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run training and evaluation:"
      ],
      "metadata": {
        "id": "0rSFCMTroHz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These code snippets train multiple neural network models (Net1, Net2, Net3, and Bonus) using the same hyperparameters (20 epochs, learning rate of 0.01) and optimization settings. Each network is created, trained using the train_test_loop function, and the loss values are stored. The training process is printed for each network, and a \"Finished Training\" message is displayed after each training session."
      ],
      "metadata": {
        "id": "x-GirVIaQxUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "lr= 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "X6kA7XkhQd1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1=Net1()\n",
        "optimizer = optim.Adam(net1.parameters(), lr=lr)\n",
        "\n",
        "print(f\"Training Network 1\")\n",
        "print(\"--------------\") \n",
        "train_losses1=train_test_loop(net1,epochs,lr,criterion,optimizer)\n",
        "print(f\"Finished Training Network 1\\n\")\n"
      ],
      "metadata": {
        "id": "OU1i2fPqncgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11127862-cadf-4e93-9a09-57a9bed26566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Network 1\n",
            "--------------\n",
            "Epoch:  1\n",
            "--------------\n",
            "loss: 2.345009  [    0/60000]\n",
            "loss: 0.239233  [ 6400/60000]\n",
            "loss: 0.202744  [12800/60000]\n",
            "loss: 0.011976  [19200/60000]\n",
            "loss: 0.136911  [25600/60000]\n",
            "loss: 0.223936  [32000/60000]\n",
            "loss: 0.178793  [38400/60000]\n",
            "loss: 0.028444  [44800/60000]\n",
            "loss: 0.034234  [51200/60000]\n",
            "loss: 0.053359  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 94.84%, Avg loss: 0.225845 \n",
            "\n",
            "Epoch:  2\n",
            "--------------\n",
            "loss: 0.135367  [    0/60000]\n",
            "loss: 0.008215  [ 6400/60000]\n",
            "loss: 0.018929  [12800/60000]\n",
            "loss: 0.004535  [19200/60000]\n",
            "loss: 0.063151  [25600/60000]\n",
            "loss: 0.013442  [32000/60000]\n",
            "loss: 0.185921  [38400/60000]\n",
            "loss: 0.047552  [44800/60000]\n",
            "loss: 0.030402  [51200/60000]\n",
            "loss: 0.097579  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 97.73%, Avg loss: 0.077627 \n",
            "\n",
            "Epoch:  3\n",
            "--------------\n",
            "loss: 0.032922  [    0/60000]\n",
            "loss: 0.009159  [ 6400/60000]\n",
            "loss: 0.011327  [12800/60000]\n",
            "loss: 0.018186  [19200/60000]\n",
            "loss: 0.048579  [25600/60000]\n",
            "loss: 0.140997  [32000/60000]\n",
            "loss: 0.020354  [38400/60000]\n",
            "loss: 0.023416  [44800/60000]\n",
            "loss: 0.034910  [51200/60000]\n",
            "loss: 0.004123  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.02%, Avg loss: 0.068648 \n",
            "\n",
            "Epoch:  4\n",
            "--------------\n",
            "loss: 0.000809  [    0/60000]\n",
            "loss: 0.011416  [ 6400/60000]\n",
            "loss: 0.017755  [12800/60000]\n",
            "loss: 0.137620  [19200/60000]\n",
            "loss: 0.015693  [25600/60000]\n",
            "loss: 0.018807  [32000/60000]\n",
            "loss: 0.053882  [38400/60000]\n",
            "loss: 0.018292  [44800/60000]\n",
            "loss: 0.063341  [51200/60000]\n",
            "loss: 0.017153  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.02%, Avg loss: 0.084657 \n",
            "\n",
            "Epoch:  5\n",
            "--------------\n",
            "loss: 0.002778  [    0/60000]\n",
            "loss: 0.090920  [ 6400/60000]\n",
            "loss: 0.026188  [12800/60000]\n",
            "loss: 0.002181  [19200/60000]\n",
            "loss: 0.000104  [25600/60000]\n",
            "loss: 0.024818  [32000/60000]\n",
            "loss: 0.120042  [38400/60000]\n",
            "loss: 0.016240  [44800/60000]\n",
            "loss: 0.028108  [51200/60000]\n",
            "loss: 0.014916  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.44%, Avg loss: 0.063090 \n",
            "\n",
            "Epoch:  6\n",
            "--------------\n",
            "loss: 0.120989  [    0/60000]\n",
            "loss: 0.004428  [ 6400/60000]\n",
            "loss: 0.010801  [12800/60000]\n",
            "loss: 0.087037  [19200/60000]\n",
            "loss: 0.006502  [25600/60000]\n",
            "loss: 0.028097  [32000/60000]\n",
            "loss: 0.043536  [38400/60000]\n",
            "loss: 0.157271  [44800/60000]\n",
            "loss: 0.026739  [51200/60000]\n",
            "loss: 0.004176  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.62%, Avg loss: 0.059464 \n",
            "\n",
            "Epoch:  7\n",
            "--------------\n",
            "loss: 0.006890  [    0/60000]\n",
            "loss: 0.000049  [ 6400/60000]\n",
            "loss: 0.051426  [12800/60000]\n",
            "loss: 0.000142  [19200/60000]\n",
            "loss: 0.000040  [25600/60000]\n",
            "loss: 0.128186  [32000/60000]\n",
            "loss: 0.091936  [38400/60000]\n",
            "loss: 0.001730  [44800/60000]\n",
            "loss: 0.026445  [51200/60000]\n",
            "loss: 0.001022  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.75%, Avg loss: 0.060638 \n",
            "\n",
            "Epoch:  8\n",
            "--------------\n",
            "loss: 0.009243  [    0/60000]\n",
            "loss: 0.107041  [ 6400/60000]\n",
            "loss: 0.000594  [12800/60000]\n",
            "loss: 0.000179  [19200/60000]\n",
            "loss: 0.226927  [25600/60000]\n",
            "loss: 0.000009  [32000/60000]\n",
            "loss: 0.000041  [38400/60000]\n",
            "loss: 0.000005  [44800/60000]\n",
            "loss: 0.000770  [51200/60000]\n",
            "loss: 0.348920  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.83%, Avg loss: 0.058002 \n",
            "\n",
            "Epoch:  9\n",
            "--------------\n",
            "loss: 0.000004  [    0/60000]\n",
            "loss: 0.000493  [ 6400/60000]\n",
            "loss: 0.000050  [12800/60000]\n",
            "loss: 0.023093  [19200/60000]\n",
            "loss: 0.084742  [25600/60000]\n",
            "loss: 0.068782  [32000/60000]\n",
            "loss: 0.000006  [38400/60000]\n",
            "loss: 0.000184  [44800/60000]\n",
            "loss: 0.031786  [51200/60000]\n",
            "loss: 0.000519  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.96%, Avg loss: 0.052361 \n",
            "\n",
            "Epoch:  10\n",
            "--------------\n",
            "loss: 0.146304  [    0/60000]\n",
            "loss: 0.000037  [ 6400/60000]\n",
            "loss: 0.105770  [12800/60000]\n",
            "loss: 0.000000  [19200/60000]\n",
            "loss: 0.104215  [25600/60000]\n",
            "loss: 0.000812  [32000/60000]\n",
            "loss: 0.000184  [38400/60000]\n",
            "loss: 0.000594  [44800/60000]\n",
            "loss: 0.000002  [51200/60000]\n",
            "loss: 0.000025  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.10%, Avg loss: 0.048040 \n",
            "\n",
            "Epoch:  11\n",
            "--------------\n",
            "loss: 0.002674  [    0/60000]\n",
            "loss: 0.000066  [ 6400/60000]\n",
            "loss: 0.000005  [12800/60000]\n",
            "loss: 0.017014  [19200/60000]\n",
            "loss: 0.000034  [25600/60000]\n",
            "loss: 0.000751  [32000/60000]\n",
            "loss: 0.217488  [38400/60000]\n",
            "loss: 0.065186  [44800/60000]\n",
            "loss: 0.051850  [51200/60000]\n",
            "loss: 0.000617  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.11%, Avg loss: 0.050780 \n",
            "\n",
            "Epoch:  12\n",
            "--------------\n",
            "loss: 0.022524  [    0/60000]\n",
            "loss: 0.000040  [ 6400/60000]\n",
            "loss: 0.000001  [12800/60000]\n",
            "loss: 0.322900  [19200/60000]\n",
            "loss: 0.000004  [25600/60000]\n",
            "loss: 0.014417  [32000/60000]\n",
            "loss: 0.001753  [38400/60000]\n",
            "loss: 0.000000  [44800/60000]\n",
            "loss: 0.000050  [51200/60000]\n",
            "loss: 0.000049  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.25%, Avg loss: 0.047188 \n",
            "\n",
            "Epoch:  13\n",
            "--------------\n",
            "loss: 0.000004  [    0/60000]\n",
            "loss: 0.003366  [ 6400/60000]\n",
            "loss: 0.150980  [12800/60000]\n",
            "loss: 0.020314  [19200/60000]\n",
            "loss: 0.001357  [25600/60000]\n",
            "loss: 0.008506  [32000/60000]\n",
            "loss: 0.014846  [38400/60000]\n",
            "loss: 0.319409  [44800/60000]\n",
            "loss: 0.000069  [51200/60000]\n",
            "loss: 0.019858  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.28%, Avg loss: 0.045992 \n",
            "\n",
            "Epoch:  14\n",
            "--------------\n",
            "loss: 0.000001  [    0/60000]\n",
            "loss: 0.003613  [ 6400/60000]\n",
            "loss: 0.497822  [12800/60000]\n",
            "loss: 0.000004  [19200/60000]\n",
            "loss: 0.046553  [25600/60000]\n",
            "loss: 0.000398  [32000/60000]\n",
            "loss: 0.000000  [38400/60000]\n",
            "loss: 0.000000  [44800/60000]\n",
            "loss: 0.000001  [51200/60000]\n",
            "loss: 0.000266  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.32%, Avg loss: 0.048310 \n",
            "\n",
            "Epoch:  15\n",
            "--------------\n",
            "loss: 0.028494  [    0/60000]\n",
            "loss: 0.002518  [ 6400/60000]\n",
            "loss: 0.003312  [12800/60000]\n",
            "loss: 0.000004  [19200/60000]\n",
            "loss: 0.000000  [25600/60000]\n",
            "loss: 0.009731  [32000/60000]\n",
            "loss: 0.000090  [38400/60000]\n",
            "loss: 0.000001  [44800/60000]\n",
            "loss: 0.058130  [51200/60000]\n",
            "loss: 0.025417  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.41%, Avg loss: 0.039364 \n",
            "\n",
            "Epoch:  16\n",
            "--------------\n",
            "loss: 0.071582  [    0/60000]\n",
            "loss: 0.000017  [ 6400/60000]\n",
            "loss: 0.001144  [12800/60000]\n",
            "loss: 0.199306  [19200/60000]\n",
            "loss: 0.010159  [25600/60000]\n",
            "loss: 0.000000  [32000/60000]\n",
            "loss: 0.050835  [38400/60000]\n",
            "loss: 0.000163  [44800/60000]\n",
            "loss: 0.000001  [51200/60000]\n",
            "loss: 0.000020  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.47%, Avg loss: 0.044894 \n",
            "\n",
            "Epoch:  17\n",
            "--------------\n",
            "loss: 0.000000  [    0/60000]\n",
            "loss: 0.000000  [ 6400/60000]\n",
            "loss: 0.000000  [12800/60000]\n",
            "loss: 0.000160  [19200/60000]\n",
            "loss: 0.000000  [25600/60000]\n",
            "loss: 0.201991  [32000/60000]\n",
            "loss: 0.140566  [38400/60000]\n",
            "loss: 0.000058  [44800/60000]\n",
            "loss: 0.000000  [51200/60000]\n",
            "loss: 0.058464  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.47%, Avg loss: 0.042825 \n",
            "\n",
            "Epoch:  18\n",
            "--------------\n",
            "loss: 0.000425  [    0/60000]\n",
            "loss: 0.002474  [ 6400/60000]\n",
            "loss: 0.000411  [12800/60000]\n",
            "loss: 0.000000  [19200/60000]\n",
            "loss: 0.000196  [25600/60000]\n",
            "loss: 0.127249  [32000/60000]\n",
            "loss: 0.000000  [38400/60000]\n",
            "loss: 0.000000  [44800/60000]\n",
            "loss: 0.000000  [51200/60000]\n",
            "loss: 0.104968  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.53%, Avg loss: 0.039770 \n",
            "\n",
            "Epoch:  19\n",
            "--------------\n",
            "loss: 0.000000  [    0/60000]\n",
            "loss: 0.046768  [ 6400/60000]\n",
            "loss: 0.000000  [12800/60000]\n",
            "loss: 0.037010  [19200/60000]\n",
            "loss: 0.062205  [25600/60000]\n",
            "loss: 0.000000  [32000/60000]\n",
            "loss: 0.050994  [38400/60000]\n",
            "loss: 0.000000  [44800/60000]\n",
            "loss: 0.310292  [51200/60000]\n",
            "loss: 0.000000  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.56%, Avg loss: 0.042164 \n",
            "\n",
            "Epoch:  20\n",
            "--------------\n",
            "loss: 0.000000  [    0/60000]\n",
            "loss: 0.000187  [ 6400/60000]\n",
            "loss: 0.079109  [12800/60000]\n",
            "loss: 0.000000  [19200/60000]\n",
            "loss: 0.000000  [25600/60000]\n",
            "loss: 0.000443  [32000/60000]\n",
            "loss: 0.000000  [38400/60000]\n",
            "loss: 0.000000  [44800/60000]\n",
            "loss: 0.006166  [51200/60000]\n",
            "loss: 0.000000  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.58%, Avg loss: 0.036885 \n",
            "\n",
            "Test Accuracy: 97.53%, Avg Test loss: 0.517097, Training Time: 5.57 minutes \n",
            "\n",
            "Finished Training Network 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net2=Net2()\n",
        "optimizer = optim.Adam(net2.parameters(), lr=lr)\n",
        "\n",
        "print(f\"Training Network 2\")\n",
        "print(\"--------------\") \n",
        "train_losses2=train_test_loop(net2,epochs,lr,criterion,optimizer)\n",
        "print(f\"Finished Training Network 2\\n\")\n"
      ],
      "metadata": {
        "id": "Fna1-JCCoCBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9845e86f-e54b-4cae-ee76-83b3d0f3d3dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Network 2\n",
            "--------------\n",
            "Epoch:  1\n",
            "--------------\n",
            "loss: 2.303062  [    0/60000]\n",
            "loss: 0.257647  [ 6400/60000]\n",
            "loss: 0.176573  [12800/60000]\n",
            "loss: 0.156160  [19200/60000]\n",
            "loss: 0.033404  [25600/60000]\n",
            "loss: 0.196200  [32000/60000]\n",
            "loss: 0.057554  [38400/60000]\n",
            "loss: 0.204686  [44800/60000]\n",
            "loss: 0.073617  [51200/60000]\n",
            "loss: 0.072436  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 95.20%, Avg loss: 0.160587 \n",
            "\n",
            "Epoch:  2\n",
            "--------------\n",
            "loss: 0.101352  [    0/60000]\n",
            "loss: 0.019056  [ 6400/60000]\n",
            "loss: 0.042979  [12800/60000]\n",
            "loss: 0.064706  [19200/60000]\n",
            "loss: 0.149065  [25600/60000]\n",
            "loss: 0.045363  [32000/60000]\n",
            "loss: 0.177812  [38400/60000]\n",
            "loss: 0.081487  [44800/60000]\n",
            "loss: 0.104640  [51200/60000]\n",
            "loss: 0.030801  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 97.50%, Avg loss: 0.088685 \n",
            "\n",
            "Epoch:  3\n",
            "--------------\n",
            "loss: 0.105157  [    0/60000]\n",
            "loss: 0.012798  [ 6400/60000]\n",
            "loss: 0.021179  [12800/60000]\n",
            "loss: 0.007718  [19200/60000]\n",
            "loss: 0.026105  [25600/60000]\n",
            "loss: 0.128694  [32000/60000]\n",
            "loss: 0.003553  [38400/60000]\n",
            "loss: 0.056376  [44800/60000]\n",
            "loss: 0.109735  [51200/60000]\n",
            "loss: 0.013211  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 97.87%, Avg loss: 0.078283 \n",
            "\n",
            "Epoch:  4\n",
            "--------------\n",
            "loss: 0.014403  [    0/60000]\n",
            "loss: 0.029751  [ 6400/60000]\n",
            "loss: 0.065864  [12800/60000]\n",
            "loss: 0.013814  [19200/60000]\n",
            "loss: 0.002945  [25600/60000]\n",
            "loss: 0.005510  [32000/60000]\n",
            "loss: 0.008013  [38400/60000]\n",
            "loss: 0.060387  [44800/60000]\n",
            "loss: 0.000407  [51200/60000]\n",
            "loss: 0.128605  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.16%, Avg loss: 0.069865 \n",
            "\n",
            "Epoch:  5\n",
            "--------------\n",
            "loss: 0.077752  [    0/60000]\n",
            "loss: 0.001461  [ 6400/60000]\n",
            "loss: 0.000644  [12800/60000]\n",
            "loss: 0.476231  [19200/60000]\n",
            "loss: 0.012522  [25600/60000]\n",
            "loss: 0.008505  [32000/60000]\n",
            "loss: 0.080075  [38400/60000]\n",
            "loss: 0.141921  [44800/60000]\n",
            "loss: 0.019641  [51200/60000]\n",
            "loss: 0.055196  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.16%, Avg loss: 0.073427 \n",
            "\n",
            "Epoch:  6\n",
            "--------------\n",
            "loss: 0.433434  [    0/60000]\n",
            "loss: 0.001243  [ 6400/60000]\n",
            "loss: 0.086695  [12800/60000]\n",
            "loss: 0.130946  [19200/60000]\n",
            "loss: 0.015482  [25600/60000]\n",
            "loss: 0.011712  [32000/60000]\n",
            "loss: 0.046185  [38400/60000]\n",
            "loss: 0.161733  [44800/60000]\n",
            "loss: 0.031553  [51200/60000]\n",
            "loss: 0.189562  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.38%, Avg loss: 0.067342 \n",
            "\n",
            "Epoch:  7\n",
            "--------------\n",
            "loss: 0.030183  [    0/60000]\n",
            "loss: 0.022856  [ 6400/60000]\n",
            "loss: 0.012996  [12800/60000]\n",
            "loss: 0.061519  [19200/60000]\n",
            "loss: 0.063403  [25600/60000]\n",
            "loss: 0.014032  [32000/60000]\n",
            "loss: 0.000149  [38400/60000]\n",
            "loss: 0.011035  [44800/60000]\n",
            "loss: 0.088665  [51200/60000]\n",
            "loss: 0.014098  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.29%, Avg loss: 0.077794 \n",
            "\n",
            "Epoch:  8\n",
            "--------------\n",
            "loss: 0.178957  [    0/60000]\n",
            "loss: 0.090117  [ 6400/60000]\n",
            "loss: 0.023944  [12800/60000]\n",
            "loss: 0.035478  [19200/60000]\n",
            "loss: 0.028228  [25600/60000]\n",
            "loss: 0.095697  [32000/60000]\n",
            "loss: 0.256288  [38400/60000]\n",
            "loss: 0.043712  [44800/60000]\n",
            "loss: 0.087300  [51200/60000]\n",
            "loss: 0.115236  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.64%, Avg loss: 0.061214 \n",
            "\n",
            "Epoch:  9\n",
            "--------------\n",
            "loss: 0.040809  [    0/60000]\n",
            "loss: 0.005342  [ 6400/60000]\n",
            "loss: 0.001357  [12800/60000]\n",
            "loss: 0.121460  [19200/60000]\n",
            "loss: 0.305172  [25600/60000]\n",
            "loss: 0.080889  [32000/60000]\n",
            "loss: 0.028819  [38400/60000]\n",
            "loss: 0.086499  [44800/60000]\n",
            "loss: 0.002189  [51200/60000]\n",
            "loss: 0.174042  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.42%, Avg loss: 0.078295 \n",
            "\n",
            "Epoch:  10\n",
            "--------------\n",
            "loss: 0.087332  [    0/60000]\n",
            "loss: 0.049128  [ 6400/60000]\n",
            "loss: 0.001361  [12800/60000]\n",
            "loss: 0.017586  [19200/60000]\n",
            "loss: 0.006178  [25600/60000]\n",
            "loss: 0.004703  [32000/60000]\n",
            "loss: 0.000084  [38400/60000]\n",
            "loss: 0.007382  [44800/60000]\n",
            "loss: 0.168365  [51200/60000]\n",
            "loss: 0.422621  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.57%, Avg loss: 0.073074 \n",
            "\n",
            "Epoch:  11\n",
            "--------------\n",
            "loss: 0.279013  [    0/60000]\n",
            "loss: 0.087182  [ 6400/60000]\n",
            "loss: 0.101480  [12800/60000]\n",
            "loss: 0.007002  [19200/60000]\n",
            "loss: 0.082632  [25600/60000]\n",
            "loss: 0.012705  [32000/60000]\n",
            "loss: 0.057626  [38400/60000]\n",
            "loss: 0.108102  [44800/60000]\n",
            "loss: 0.026867  [51200/60000]\n",
            "loss: 0.023347  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.66%, Avg loss: 0.072353 \n",
            "\n",
            "Epoch:  12\n",
            "--------------\n",
            "loss: 0.020160  [    0/60000]\n",
            "loss: 0.000188  [ 6400/60000]\n",
            "loss: 0.090814  [12800/60000]\n",
            "loss: 0.006086  [19200/60000]\n",
            "loss: 0.000139  [25600/60000]\n",
            "loss: 0.001170  [32000/60000]\n",
            "loss: 0.006954  [38400/60000]\n",
            "loss: 0.084449  [44800/60000]\n",
            "loss: 0.000750  [51200/60000]\n",
            "loss: 0.004502  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.87%, Avg loss: 0.066507 \n",
            "\n",
            "Epoch:  13\n",
            "--------------\n",
            "loss: 0.000688  [    0/60000]\n",
            "loss: 0.007878  [ 6400/60000]\n",
            "loss: 0.056329  [12800/60000]\n",
            "loss: 0.000615  [19200/60000]\n",
            "loss: 0.724742  [25600/60000]\n",
            "loss: 0.000006  [32000/60000]\n",
            "loss: 0.477603  [38400/60000]\n",
            "loss: 0.000016  [44800/60000]\n",
            "loss: 0.000105  [51200/60000]\n",
            "loss: 0.002472  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.79%, Avg loss: 0.080135 \n",
            "\n",
            "Epoch:  14\n",
            "--------------\n",
            "loss: 0.000095  [    0/60000]\n",
            "loss: 0.000001  [ 6400/60000]\n",
            "loss: 0.033853  [12800/60000]\n",
            "loss: 0.055340  [19200/60000]\n",
            "loss: 0.109359  [25600/60000]\n",
            "loss: 0.650556  [32000/60000]\n",
            "loss: 0.000139  [38400/60000]\n",
            "loss: 0.011728  [44800/60000]\n",
            "loss: 0.001180  [51200/60000]\n",
            "loss: 0.005807  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.62%, Avg loss: 0.106898 \n",
            "\n",
            "Epoch:  15\n",
            "--------------\n",
            "loss: 0.000213  [    0/60000]\n",
            "loss: 0.000849  [ 6400/60000]\n",
            "loss: 0.005384  [12800/60000]\n",
            "loss: 0.000000  [19200/60000]\n",
            "loss: 0.039742  [25600/60000]\n",
            "loss: 0.075887  [32000/60000]\n",
            "loss: 0.155677  [38400/60000]\n",
            "loss: 0.004994  [44800/60000]\n",
            "loss: 0.041534  [51200/60000]\n",
            "loss: 0.247762  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.14%, Avg loss: 0.051638 \n",
            "\n",
            "Epoch:  16\n",
            "--------------\n",
            "loss: 0.037148  [    0/60000]\n",
            "loss: 0.121990  [ 6400/60000]\n",
            "loss: 0.389018  [12800/60000]\n",
            "loss: 0.000000  [19200/60000]\n",
            "loss: 0.150879  [25600/60000]\n",
            "loss: 0.107063  [32000/60000]\n",
            "loss: 0.175495  [38400/60000]\n",
            "loss: 0.763073  [44800/60000]\n",
            "loss: 0.124292  [51200/60000]\n",
            "loss: 0.047462  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.79%, Avg loss: 0.094277 \n",
            "\n",
            "Epoch:  17\n",
            "--------------\n",
            "loss: 0.000069  [    0/60000]\n",
            "loss: 0.032444  [ 6400/60000]\n",
            "loss: 0.002144  [12800/60000]\n",
            "loss: 0.097633  [19200/60000]\n",
            "loss: 0.344226  [25600/60000]\n",
            "loss: 0.000168  [32000/60000]\n",
            "loss: 0.043929  [38400/60000]\n",
            "loss: 0.095763  [44800/60000]\n",
            "loss: 0.842454  [51200/60000]\n",
            "loss: 0.175744  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.78%, Avg loss: 0.101173 \n",
            "\n",
            "Epoch:  18\n",
            "--------------\n",
            "loss: 0.015020  [    0/60000]\n",
            "loss: 0.015190  [ 6400/60000]\n",
            "loss: 0.000112  [12800/60000]\n",
            "loss: 0.030245  [19200/60000]\n",
            "loss: 0.025841  [25600/60000]\n",
            "loss: 1.174027  [32000/60000]\n",
            "loss: 0.085094  [38400/60000]\n",
            "loss: 0.000023  [44800/60000]\n",
            "loss: 0.042520  [51200/60000]\n",
            "loss: 0.664344  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.83%, Avg loss: 0.098101 \n",
            "\n",
            "Epoch:  19\n",
            "--------------\n",
            "loss: 0.094926  [    0/60000]\n",
            "loss: 0.094870  [ 6400/60000]\n",
            "loss: 0.348731  [12800/60000]\n",
            "loss: 0.000000  [19200/60000]\n",
            "loss: 0.000028  [25600/60000]\n",
            "loss: 0.041718  [32000/60000]\n",
            "loss: 0.000261  [38400/60000]\n",
            "loss: 0.073482  [44800/60000]\n",
            "loss: 0.010993  [51200/60000]\n",
            "loss: 0.212951  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.91%, Avg loss: 0.082696 \n",
            "\n",
            "Epoch:  20\n",
            "--------------\n",
            "loss: 0.000000  [    0/60000]\n",
            "loss: 0.334393  [ 6400/60000]\n",
            "loss: 0.000158  [12800/60000]\n",
            "loss: 0.000000  [19200/60000]\n",
            "loss: 0.044713  [25600/60000]\n",
            "loss: 0.432656  [32000/60000]\n",
            "loss: 0.000000  [38400/60000]\n",
            "loss: 0.051114  [44800/60000]\n",
            "loss: 0.224529  [51200/60000]\n",
            "loss: 0.084035  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.82%, Avg loss: 0.115908 \n",
            "\n",
            "Test Accuracy: 97.85%, Avg Test loss: 0.375264, Training Time: 5.76 minutes \n",
            "\n",
            "Finished Training Network 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net3=Net3()\n",
        "optimizer = optim.Adam(net3.parameters(), lr=lr)\n",
        "\n",
        "print(f\"Training Network 3\")\n",
        "print(\"--------------\") \n",
        "train_losses3=train_test_loop(net3,epochs,lr,criterion,optimizer)\n",
        "print(f\"Finished Training Network 3\\n\")\n"
      ],
      "metadata": {
        "id": "GOeybg58oCmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404270a4-58a0-47ae-c3a3-a221699ccc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Network 3\n",
            "--------------\n",
            "Epoch:  1\n",
            "--------------\n",
            "loss: 2.335370  [    0/60000]\n",
            "loss: 0.252432  [ 6400/60000]\n",
            "loss: 0.228032  [12800/60000]\n",
            "loss: 0.022070  [19200/60000]\n",
            "loss: 0.202308  [25600/60000]\n",
            "loss: 0.015645  [32000/60000]\n",
            "loss: 0.131420  [38400/60000]\n",
            "loss: 0.034878  [44800/60000]\n",
            "loss: 0.010058  [51200/60000]\n",
            "loss: 0.028678  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 93.97%, Avg loss: 0.185372 \n",
            "\n",
            "Epoch:  2\n",
            "--------------\n",
            "loss: 0.091281  [    0/60000]\n",
            "loss: 0.065126  [ 6400/60000]\n",
            "loss: 0.053839  [12800/60000]\n",
            "loss: 0.136430  [19200/60000]\n",
            "loss: 0.172828  [25600/60000]\n",
            "loss: 0.137644  [32000/60000]\n",
            "loss: 0.037939  [38400/60000]\n",
            "loss: 0.009870  [44800/60000]\n",
            "loss: 0.006453  [51200/60000]\n",
            "loss: 0.075747  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.02%, Avg loss: 0.068314 \n",
            "\n",
            "Epoch:  3\n",
            "--------------\n",
            "loss: 0.036647  [    0/60000]\n",
            "loss: 0.019313  [ 6400/60000]\n",
            "loss: 0.087830  [12800/60000]\n",
            "loss: 0.162716  [19200/60000]\n",
            "loss: 0.008370  [25600/60000]\n",
            "loss: 0.023044  [32000/60000]\n",
            "loss: 0.089547  [38400/60000]\n",
            "loss: 0.002520  [44800/60000]\n",
            "loss: 0.099622  [51200/60000]\n",
            "loss: 0.025219  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.23%, Avg loss: 0.060336 \n",
            "\n",
            "Epoch:  4\n",
            "--------------\n",
            "loss: 0.078350  [    0/60000]\n",
            "loss: 0.028672  [ 6400/60000]\n",
            "loss: 0.027078  [12800/60000]\n",
            "loss: 0.008738  [19200/60000]\n",
            "loss: 0.072887  [25600/60000]\n",
            "loss: 0.129533  [32000/60000]\n",
            "loss: 0.088954  [38400/60000]\n",
            "loss: 0.007093  [44800/60000]\n",
            "loss: 0.046193  [51200/60000]\n",
            "loss: 0.142085  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.47%, Avg loss: 0.054145 \n",
            "\n",
            "Epoch:  5\n",
            "--------------\n",
            "loss: 0.158752  [    0/60000]\n",
            "loss: 0.018523  [ 6400/60000]\n",
            "loss: 0.055877  [12800/60000]\n",
            "loss: 0.000205  [19200/60000]\n",
            "loss: 0.022349  [25600/60000]\n",
            "loss: 0.012357  [32000/60000]\n",
            "loss: 0.015007  [38400/60000]\n",
            "loss: 0.020959  [44800/60000]\n",
            "loss: 0.034794  [51200/60000]\n",
            "loss: 0.054669  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.67%, Avg loss: 0.046622 \n",
            "\n",
            "Epoch:  6\n",
            "--------------\n",
            "loss: 0.008902  [    0/60000]\n",
            "loss: 0.007915  [ 6400/60000]\n",
            "loss: 0.000114  [12800/60000]\n",
            "loss: 0.070104  [19200/60000]\n",
            "loss: 0.019538  [25600/60000]\n",
            "loss: 0.171928  [32000/60000]\n",
            "loss: 0.149398  [38400/60000]\n",
            "loss: 0.004428  [44800/60000]\n",
            "loss: 0.096272  [51200/60000]\n",
            "loss: 0.029387  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.76%, Avg loss: 0.043758 \n",
            "\n",
            "Epoch:  7\n",
            "--------------\n",
            "loss: 0.106692  [    0/60000]\n",
            "loss: 0.126197  [ 6400/60000]\n",
            "loss: 0.066588  [12800/60000]\n",
            "loss: 0.016283  [19200/60000]\n",
            "loss: 0.015071  [25600/60000]\n",
            "loss: 0.046106  [32000/60000]\n",
            "loss: 0.044678  [38400/60000]\n",
            "loss: 0.009957  [44800/60000]\n",
            "loss: 0.038060  [51200/60000]\n",
            "loss: 0.012434  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.78%, Avg loss: 0.041250 \n",
            "\n",
            "Epoch:  8\n",
            "--------------\n",
            "loss: 0.000459  [    0/60000]\n",
            "loss: 0.020586  [ 6400/60000]\n",
            "loss: 0.026529  [12800/60000]\n",
            "loss: 0.028727  [19200/60000]\n",
            "loss: 0.008374  [25600/60000]\n",
            "loss: 0.001669  [32000/60000]\n",
            "loss: 0.000418  [38400/60000]\n",
            "loss: 0.116281  [44800/60000]\n",
            "loss: 0.212652  [51200/60000]\n",
            "loss: 0.013584  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.93%, Avg loss: 0.038299 \n",
            "\n",
            "Epoch:  9\n",
            "--------------\n",
            "loss: 0.008691  [    0/60000]\n",
            "loss: 0.001500  [ 6400/60000]\n",
            "loss: 0.308691  [12800/60000]\n",
            "loss: 0.023819  [19200/60000]\n",
            "loss: 0.072075  [25600/60000]\n",
            "loss: 0.004052  [32000/60000]\n",
            "loss: 0.004332  [38400/60000]\n",
            "loss: 0.001526  [44800/60000]\n",
            "loss: 0.000238  [51200/60000]\n",
            "loss: 0.009983  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.92%, Avg loss: 0.038155 \n",
            "\n",
            "Epoch:  10\n",
            "--------------\n",
            "loss: 0.009829  [    0/60000]\n",
            "loss: 0.088521  [ 6400/60000]\n",
            "loss: 0.001193  [12800/60000]\n",
            "loss: 0.061896  [19200/60000]\n",
            "loss: 0.001934  [25600/60000]\n",
            "loss: 0.050409  [32000/60000]\n",
            "loss: 0.113854  [38400/60000]\n",
            "loss: 0.013140  [44800/60000]\n",
            "loss: 0.002412  [51200/60000]\n",
            "loss: 0.033605  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.06%, Avg loss: 0.034065 \n",
            "\n",
            "Epoch:  11\n",
            "--------------\n",
            "loss: 0.078092  [    0/60000]\n",
            "loss: 0.174378  [ 6400/60000]\n",
            "loss: 0.024691  [12800/60000]\n",
            "loss: 0.025252  [19200/60000]\n",
            "loss: 0.089553  [25600/60000]\n",
            "loss: 0.002874  [32000/60000]\n",
            "loss: 0.013452  [38400/60000]\n",
            "loss: 0.002402  [44800/60000]\n",
            "loss: 0.038876  [51200/60000]\n",
            "loss: 0.001659  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.15%, Avg loss: 0.031373 \n",
            "\n",
            "Epoch:  12\n",
            "--------------\n",
            "loss: 0.075385  [    0/60000]\n",
            "loss: 0.004308  [ 6400/60000]\n",
            "loss: 0.007887  [12800/60000]\n",
            "loss: 0.010256  [19200/60000]\n",
            "loss: 0.056782  [25600/60000]\n",
            "loss: 0.060735  [32000/60000]\n",
            "loss: 0.002844  [38400/60000]\n",
            "loss: 0.013075  [44800/60000]\n",
            "loss: 0.082903  [51200/60000]\n",
            "loss: 0.051992  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.06%, Avg loss: 0.035092 \n",
            "\n",
            "Epoch:  13\n",
            "--------------\n",
            "loss: 0.002071  [    0/60000]\n",
            "loss: 0.004886  [ 6400/60000]\n",
            "loss: 0.026435  [12800/60000]\n",
            "loss: 0.069302  [19200/60000]\n",
            "loss: 0.036477  [25600/60000]\n",
            "loss: 0.037960  [32000/60000]\n",
            "loss: 0.006344  [38400/60000]\n",
            "loss: 0.029518  [44800/60000]\n",
            "loss: 0.025212  [51200/60000]\n",
            "loss: 0.065380  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.22%, Avg loss: 0.028312 \n",
            "\n",
            "Epoch:  14\n",
            "--------------\n",
            "loss: 0.006397  [    0/60000]\n",
            "loss: 0.014810  [ 6400/60000]\n",
            "loss: 0.107861  [12800/60000]\n",
            "loss: 0.004974  [19200/60000]\n",
            "loss: 0.042220  [25600/60000]\n",
            "loss: 0.004073  [32000/60000]\n",
            "loss: 0.025785  [38400/60000]\n",
            "loss: 0.002180  [44800/60000]\n",
            "loss: 0.001851  [51200/60000]\n",
            "loss: 0.002537  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.22%, Avg loss: 0.029344 \n",
            "\n",
            "Epoch:  15\n",
            "--------------\n",
            "loss: 0.002556  [    0/60000]\n",
            "loss: 0.000388  [ 6400/60000]\n",
            "loss: 0.001323  [12800/60000]\n",
            "loss: 0.000201  [19200/60000]\n",
            "loss: 0.011128  [25600/60000]\n",
            "loss: 0.035137  [32000/60000]\n",
            "loss: 0.026325  [38400/60000]\n",
            "loss: 0.000799  [44800/60000]\n",
            "loss: 0.000065  [51200/60000]\n",
            "loss: 0.002096  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.24%, Avg loss: 0.026652 \n",
            "\n",
            "Epoch:  16\n",
            "--------------\n",
            "loss: 0.027804  [    0/60000]\n",
            "loss: 0.008510  [ 6400/60000]\n",
            "loss: 0.002904  [12800/60000]\n",
            "loss: 0.080347  [19200/60000]\n",
            "loss: 0.171617  [25600/60000]\n",
            "loss: 0.048804  [32000/60000]\n",
            "loss: 0.008755  [38400/60000]\n",
            "loss: 0.006939  [44800/60000]\n",
            "loss: 0.003749  [51200/60000]\n",
            "loss: 0.063330  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.25%, Avg loss: 0.028258 \n",
            "\n",
            "Epoch:  17\n",
            "--------------\n",
            "loss: 0.016556  [    0/60000]\n",
            "loss: 0.144231  [ 6400/60000]\n",
            "loss: 0.003026  [12800/60000]\n",
            "loss: 0.001103  [19200/60000]\n",
            "loss: 0.035540  [25600/60000]\n",
            "loss: 0.047437  [32000/60000]\n",
            "loss: 0.059138  [38400/60000]\n",
            "loss: 0.021671  [44800/60000]\n",
            "loss: 0.004328  [51200/60000]\n",
            "loss: 0.000224  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.27%, Avg loss: 0.026201 \n",
            "\n",
            "Epoch:  18\n",
            "--------------\n",
            "loss: 0.031398  [    0/60000]\n",
            "loss: 0.000524  [ 6400/60000]\n",
            "loss: 0.001199  [12800/60000]\n",
            "loss: 0.001272  [19200/60000]\n",
            "loss: 0.001306  [25600/60000]\n",
            "loss: 0.001173  [32000/60000]\n",
            "loss: 0.045565  [38400/60000]\n",
            "loss: 0.009219  [44800/60000]\n",
            "loss: 0.000694  [51200/60000]\n",
            "loss: 0.005616  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.36%, Avg loss: 0.024404 \n",
            "\n",
            "Epoch:  19\n",
            "--------------\n",
            "loss: 0.113785  [    0/60000]\n",
            "loss: 0.000339  [ 6400/60000]\n",
            "loss: 0.023756  [12800/60000]\n",
            "loss: 0.007099  [19200/60000]\n",
            "loss: 0.002394  [25600/60000]\n",
            "loss: 0.000178  [32000/60000]\n",
            "loss: 0.110313  [38400/60000]\n",
            "loss: 0.001112  [44800/60000]\n",
            "loss: 0.004044  [51200/60000]\n",
            "loss: 0.000653  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.36%, Avg loss: 0.023947 \n",
            "\n",
            "Epoch:  20\n",
            "--------------\n",
            "loss: 0.011503  [    0/60000]\n",
            "loss: 0.000070  [ 6400/60000]\n",
            "loss: 0.013577  [12800/60000]\n",
            "loss: 0.003743  [19200/60000]\n",
            "loss: 0.000034  [25600/60000]\n",
            "loss: 0.000194  [32000/60000]\n",
            "loss: 0.029957  [38400/60000]\n",
            "loss: 0.125614  [44800/60000]\n",
            "loss: 0.025856  [51200/60000]\n",
            "loss: 0.000056  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 99.35%, Avg loss: 0.026054 \n",
            "\n",
            "Test Accuracy: 98.99%, Avg Test loss: 0.048471, Training Time: 5.74 minutes \n",
            "\n",
            "Finished Training Network 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bonus=Bonus()\n",
        "optimizer = optim.Adam(bonus.parameters(), lr=lr)\n",
        "\n",
        "print(f\"Bonus Network\")\n",
        "print(\"--------------\") \n",
        "bonus_losses=train_test_loop(bonus,epochs,lr,criterion,optimizer)\n",
        "print(f\"Finished Training Bonus Network\\n\")\n"
      ],
      "metadata": {
        "id": "yMotwm6EIR6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05c3f00-01d8-47eb-c8ba-e01bab8a204f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonus Network\n",
            "--------------\n",
            "Epoch:  1\n",
            "--------------\n",
            "loss: 2.334696  [    0/60000]\n",
            "loss: 0.494700  [ 6400/60000]\n",
            "loss: 0.399079  [12800/60000]\n",
            "loss: 0.500582  [19200/60000]\n",
            "loss: 0.176117  [25600/60000]\n",
            "loss: 0.118454  [32000/60000]\n",
            "loss: 0.227607  [38400/60000]\n",
            "loss: 0.101551  [44800/60000]\n",
            "loss: 0.172351  [51200/60000]\n",
            "loss: 0.485190  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 91.38%, Avg loss: 0.290357 \n",
            "\n",
            "Epoch:  2\n",
            "--------------\n",
            "loss: 0.142917  [    0/60000]\n",
            "loss: 0.111168  [ 6400/60000]\n",
            "loss: 0.149090  [12800/60000]\n",
            "loss: 0.036165  [19200/60000]\n",
            "loss: 0.067338  [25600/60000]\n",
            "loss: 0.020781  [32000/60000]\n",
            "loss: 0.187166  [38400/60000]\n",
            "loss: 0.074264  [44800/60000]\n",
            "loss: 0.228162  [51200/60000]\n",
            "loss: 0.117457  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 96.94%, Avg loss: 0.113426 \n",
            "\n",
            "Epoch:  3\n",
            "--------------\n",
            "loss: 0.020276  [    0/60000]\n",
            "loss: 0.110360  [ 6400/60000]\n",
            "loss: 0.001852  [12800/60000]\n",
            "loss: 0.091792  [19200/60000]\n",
            "loss: 0.139854  [25600/60000]\n",
            "loss: 0.078840  [32000/60000]\n",
            "loss: 0.024190  [38400/60000]\n",
            "loss: 0.119830  [44800/60000]\n",
            "loss: 0.140150  [51200/60000]\n",
            "loss: 0.131861  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 97.36%, Avg loss: 0.098108 \n",
            "\n",
            "Epoch:  4\n",
            "--------------\n",
            "loss: 0.222200  [    0/60000]\n",
            "loss: 0.017499  [ 6400/60000]\n",
            "loss: 0.044326  [12800/60000]\n",
            "loss: 0.241533  [19200/60000]\n",
            "loss: 0.119634  [25600/60000]\n",
            "loss: 0.108615  [32000/60000]\n",
            "loss: 0.131581  [38400/60000]\n",
            "loss: 0.030009  [44800/60000]\n",
            "loss: 0.009913  [51200/60000]\n",
            "loss: 0.015591  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 97.62%, Avg loss: 0.089109 \n",
            "\n",
            "Epoch:  5\n",
            "--------------\n",
            "loss: 0.082633  [    0/60000]\n",
            "loss: 0.722976  [ 6400/60000]\n",
            "loss: 0.145424  [12800/60000]\n",
            "loss: 0.028285  [19200/60000]\n",
            "loss: 0.046828  [25600/60000]\n",
            "loss: 0.092980  [32000/60000]\n",
            "loss: 0.024964  [38400/60000]\n",
            "loss: 0.018743  [44800/60000]\n",
            "loss: 0.097066  [51200/60000]\n",
            "loss: 0.046898  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 97.81%, Avg loss: 0.084380 \n",
            "\n",
            "Epoch:  6\n",
            "--------------\n",
            "loss: 0.025296  [    0/60000]\n",
            "loss: 0.009790  [ 6400/60000]\n",
            "loss: 0.123459  [12800/60000]\n",
            "loss: 0.034197  [19200/60000]\n",
            "loss: 0.029467  [25600/60000]\n",
            "loss: 0.018559  [32000/60000]\n",
            "loss: 0.021568  [38400/60000]\n",
            "loss: 0.016538  [44800/60000]\n",
            "loss: 0.027851  [51200/60000]\n",
            "loss: 0.040504  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 97.98%, Avg loss: 0.078607 \n",
            "\n",
            "Epoch:  7\n",
            "--------------\n",
            "loss: 0.095257  [    0/60000]\n",
            "loss: 0.061182  [ 6400/60000]\n",
            "loss: 0.027858  [12800/60000]\n",
            "loss: 0.058066  [19200/60000]\n",
            "loss: 0.008744  [25600/60000]\n",
            "loss: 0.004125  [32000/60000]\n",
            "loss: 0.044128  [38400/60000]\n",
            "loss: 0.165503  [44800/60000]\n",
            "loss: 0.200935  [51200/60000]\n",
            "loss: 0.050869  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 97.98%, Avg loss: 0.079220 \n",
            "\n",
            "Epoch:  8\n",
            "--------------\n",
            "loss: 0.027259  [    0/60000]\n",
            "loss: 0.044421  [ 6400/60000]\n",
            "loss: 0.025799  [12800/60000]\n",
            "loss: 0.037236  [19200/60000]\n",
            "loss: 0.041310  [25600/60000]\n",
            "loss: 0.329342  [32000/60000]\n",
            "loss: 0.008989  [38400/60000]\n",
            "loss: 0.073491  [44800/60000]\n",
            "loss: 0.088974  [51200/60000]\n",
            "loss: 0.054620  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.15%, Avg loss: 0.072066 \n",
            "\n",
            "Epoch:  9\n",
            "--------------\n",
            "loss: 0.028821  [    0/60000]\n",
            "loss: 0.013009  [ 6400/60000]\n",
            "loss: 0.061114  [12800/60000]\n",
            "loss: 0.196168  [19200/60000]\n",
            "loss: 0.023953  [25600/60000]\n",
            "loss: 0.018388  [32000/60000]\n",
            "loss: 0.083994  [38400/60000]\n",
            "loss: 0.002125  [44800/60000]\n",
            "loss: 0.217119  [51200/60000]\n",
            "loss: 0.010038  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.07%, Avg loss: 0.077815 \n",
            "\n",
            "Epoch:  10\n",
            "--------------\n",
            "loss: 0.055083  [    0/60000]\n",
            "loss: 0.054351  [ 6400/60000]\n",
            "loss: 0.005301  [12800/60000]\n",
            "loss: 0.058415  [19200/60000]\n",
            "loss: 0.050247  [25600/60000]\n",
            "loss: 0.015556  [32000/60000]\n",
            "loss: 0.097329  [38400/60000]\n",
            "loss: 0.066744  [44800/60000]\n",
            "loss: 0.237354  [51200/60000]\n",
            "loss: 0.037869  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.11%, Avg loss: 0.071284 \n",
            "\n",
            "Epoch:  11\n",
            "--------------\n",
            "loss: 0.028390  [    0/60000]\n",
            "loss: 0.096834  [ 6400/60000]\n",
            "loss: 0.013685  [12800/60000]\n",
            "loss: 0.083533  [19200/60000]\n",
            "loss: 0.024282  [25600/60000]\n",
            "loss: 0.152378  [32000/60000]\n",
            "loss: 0.016146  [38400/60000]\n",
            "loss: 0.006889  [44800/60000]\n",
            "loss: 0.037392  [51200/60000]\n",
            "loss: 0.040882  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.23%, Avg loss: 0.070004 \n",
            "\n",
            "Epoch:  12\n",
            "--------------\n",
            "loss: 0.098040  [    0/60000]\n",
            "loss: 0.414704  [ 6400/60000]\n",
            "loss: 0.016333  [12800/60000]\n",
            "loss: 0.000820  [19200/60000]\n",
            "loss: 0.002596  [25600/60000]\n",
            "loss: 0.135269  [32000/60000]\n",
            "loss: 0.027850  [38400/60000]\n",
            "loss: 0.047899  [44800/60000]\n",
            "loss: 0.000075  [51200/60000]\n",
            "loss: 0.075828  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.23%, Avg loss: 0.067058 \n",
            "\n",
            "Epoch:  13\n",
            "--------------\n",
            "loss: 0.473086  [    0/60000]\n",
            "loss: 0.008023  [ 6400/60000]\n",
            "loss: 0.008551  [12800/60000]\n",
            "loss: 0.016860  [19200/60000]\n",
            "loss: 0.064795  [25600/60000]\n",
            "loss: 0.003335  [32000/60000]\n",
            "loss: 0.025461  [38400/60000]\n",
            "loss: 0.074683  [44800/60000]\n",
            "loss: 0.065052  [51200/60000]\n",
            "loss: 0.002626  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.28%, Avg loss: 0.065945 \n",
            "\n",
            "Epoch:  14\n",
            "--------------\n",
            "loss: 0.012710  [    0/60000]\n",
            "loss: 0.047163  [ 6400/60000]\n",
            "loss: 0.069570  [12800/60000]\n",
            "loss: 0.001343  [19200/60000]\n",
            "loss: 0.016205  [25600/60000]\n",
            "loss: 0.142799  [32000/60000]\n",
            "loss: 0.020406  [38400/60000]\n",
            "loss: 0.034664  [44800/60000]\n",
            "loss: 0.035730  [51200/60000]\n",
            "loss: 0.024651  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.33%, Avg loss: 0.068710 \n",
            "\n",
            "Epoch:  15\n",
            "--------------\n",
            "loss: 0.286502  [    0/60000]\n",
            "loss: 0.063017  [ 6400/60000]\n",
            "loss: 0.033167  [12800/60000]\n",
            "loss: 0.021963  [19200/60000]\n",
            "loss: 0.000875  [25600/60000]\n",
            "loss: 0.197830  [32000/60000]\n",
            "loss: 0.013987  [38400/60000]\n",
            "loss: 0.067964  [44800/60000]\n",
            "loss: 0.107635  [51200/60000]\n",
            "loss: 0.039391  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.32%, Avg loss: 0.066724 \n",
            "\n",
            "Epoch:  16\n",
            "--------------\n",
            "loss: 0.001356  [    0/60000]\n",
            "loss: 0.019139  [ 6400/60000]\n",
            "loss: 0.006517  [12800/60000]\n",
            "loss: 0.008404  [19200/60000]\n",
            "loss: 0.114888  [25600/60000]\n",
            "loss: 0.026502  [32000/60000]\n",
            "loss: 0.056374  [38400/60000]\n",
            "loss: 0.022831  [44800/60000]\n",
            "loss: 0.098196  [51200/60000]\n",
            "loss: 0.034577  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.32%, Avg loss: 0.063499 \n",
            "\n",
            "Epoch:  17\n",
            "--------------\n",
            "loss: 0.024041  [    0/60000]\n",
            "loss: 0.075380  [ 6400/60000]\n",
            "loss: 0.056130  [12800/60000]\n",
            "loss: 0.083850  [19200/60000]\n",
            "loss: 0.156435  [25600/60000]\n",
            "loss: 0.009308  [32000/60000]\n",
            "loss: 0.024831  [38400/60000]\n",
            "loss: 0.022961  [44800/60000]\n",
            "loss: 0.155157  [51200/60000]\n",
            "loss: 0.005238  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.47%, Avg loss: 0.060249 \n",
            "\n",
            "Epoch:  18\n",
            "--------------\n",
            "loss: 0.037176  [    0/60000]\n",
            "loss: 0.024777  [ 6400/60000]\n",
            "loss: 0.008277  [12800/60000]\n",
            "loss: 0.007153  [19200/60000]\n",
            "loss: 0.059208  [25600/60000]\n",
            "loss: 0.172329  [32000/60000]\n",
            "loss: 0.033094  [38400/60000]\n",
            "loss: 0.008318  [44800/60000]\n",
            "loss: 0.063920  [51200/60000]\n",
            "loss: 0.102608  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.48%, Avg loss: 0.060798 \n",
            "\n",
            "Epoch:  19\n",
            "--------------\n",
            "loss: 0.013827  [    0/60000]\n",
            "loss: 0.010166  [ 6400/60000]\n",
            "loss: 0.008021  [12800/60000]\n",
            "loss: 0.088830  [19200/60000]\n",
            "loss: 0.030938  [25600/60000]\n",
            "loss: 0.058882  [32000/60000]\n",
            "loss: 0.186593  [38400/60000]\n",
            "loss: 0.021192  [44800/60000]\n",
            "loss: 0.149621  [51200/60000]\n",
            "loss: 0.046612  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.51%, Avg loss: 0.057758 \n",
            "\n",
            "Epoch:  20\n",
            "--------------\n",
            "loss: 0.019929  [    0/60000]\n",
            "loss: 0.182429  [ 6400/60000]\n",
            "loss: 0.023227  [12800/60000]\n",
            "loss: 0.001785  [19200/60000]\n",
            "loss: 0.015073  [25600/60000]\n",
            "loss: 0.028178  [32000/60000]\n",
            "loss: 0.072564  [38400/60000]\n",
            "loss: 0.029709  [44800/60000]\n",
            "loss: 0.025688  [51200/60000]\n",
            "loss: 0.070057  [57600/60000]\n",
            "Train Error: \n",
            " Accuracy: 98.30%, Avg loss: 0.066879 \n",
            "\n",
            "Test Accuracy: 98.74%, Avg Test loss: 0.053674, Training Time: 5.84 minutes \n",
            "\n",
            "Finished Training Bonus Network\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summary of Networks:"
      ],
      "metadata": {
        "id": "EOK4sPoIFkfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These code use PyTorch summary to analyze and summarize the architecture of neural network models. It provides information about the number of parameters and output shapes for each layer. This helps in understanding the complexity and structure of the models."
      ],
      "metadata": {
        "id": "HAKdJlLLQQhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Network #1\n",
        "\n",
        "summary(net1,input_size=(batch_size,1,28,28),device=device,col_names=['input_size', 'output_size','num_params'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "r3zL_F6WGUv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2202c8f2-065a-4762-a228-9f3a174a29e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.10/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
              "===================================================================================================================\n",
              "Net1                                     [64, 1, 28, 28]           [64, 10]                  --\n",
              "├─Conv2d: 1-1                            [64, 1, 28, 28]           [64, 16, 28, 28]          416\n",
              "├─ReLU: 1-2                              [64, 16, 28, 28]          [64, 16, 28, 28]          --\n",
              "├─Flatten: 1-3                           [64, 16, 28, 28]          [64, 12544]               --\n",
              "├─Linear: 1-4                            [64, 12544]               [64, 10]                  125,450\n",
              "===================================================================================================================\n",
              "Total params: 125,866\n",
              "Trainable params: 125,866\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 28.90\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 6.43\n",
              "Params size (MB): 0.50\n",
              "Estimated Total Size (MB): 7.13\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Network #2\n",
        "summary(net2,input_size=(batch_size,1,28,28),device=device,col_names=['input_size', 'output_size','num_params'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rr_d7TsZFoIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2f6d1c-434c-4415-9229-2896a55c373e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
              "===================================================================================================================\n",
              "Net2                                     [64, 1, 28, 28]           [64, 10]                  --\n",
              "├─Conv2d: 1-1                            [64, 1, 28, 28]           [64, 6, 28, 28]           156\n",
              "├─ReLU: 1-2                              [64, 6, 28, 28]           [64, 6, 28, 28]           --\n",
              "├─Conv2d: 1-3                            [64, 6, 28, 28]           [64, 16, 28, 28]          2,416\n",
              "├─ReLU: 1-4                              [64, 16, 28, 28]          [64, 16, 28, 28]          --\n",
              "├─Flatten: 1-5                           [64, 16, 28, 28]          [64, 12544]               --\n",
              "├─Linear: 1-6                            [64, 12544]               [64, 84]                  1,053,780\n",
              "├─ReLU: 1-7                              [64, 84]                  [64, 84]                  --\n",
              "├─Linear: 1-8                            [64, 84]                  [64, 10]                  850\n",
              "===================================================================================================================\n",
              "Total params: 1,057,202\n",
              "Trainable params: 1,057,202\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 196.55\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 8.88\n",
              "Params size (MB): 4.23\n",
              "Estimated Total Size (MB): 13.31\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Network #3\n",
        "summary(net3,input_size=(batch_size,1,28,28),device=device,col_names=['input_size', 'output_size','num_params'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mKEpfgXQGrrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0692137-07cd-4726-86a7-b7fb349c9090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
              "===================================================================================================================\n",
              "Net3                                     [64, 1, 28, 28]           [64, 10]                  --\n",
              "├─Conv2d: 1-1                            [64, 1, 28, 28]           [64, 6, 28, 28]           156\n",
              "├─BatchNorm2d: 1-2                       [64, 6, 28, 28]           [64, 6, 28, 28]           12\n",
              "├─ReLU: 1-3                              [64, 6, 28, 28]           [64, 6, 28, 28]           --\n",
              "├─MaxPool2d: 1-4                         [64, 6, 28, 28]           [64, 6, 14, 14]           --\n",
              "├─Conv2d: 1-5                            [64, 6, 14, 14]           [64, 16, 14, 14]          2,416\n",
              "├─BatchNorm2d: 1-6                       [64, 16, 14, 14]          [64, 16, 14, 14]          32\n",
              "├─ReLU: 1-7                              [64, 16, 14, 14]          [64, 16, 14, 14]          --\n",
              "├─MaxPool2d: 1-8                         [64, 16, 14, 14]          [64, 16, 7, 7]            --\n",
              "├─Flatten: 1-9                           [64, 16, 7, 7]            [64, 784]                 --\n",
              "├─Linear: 1-10                           [64, 784]                 [64, 120]                 94,200\n",
              "├─ReLU: 1-11                             [64, 120]                 [64, 120]                 --\n",
              "├─Linear: 1-12                           [64, 120]                 [64, 84]                  10,164\n",
              "├─ReLU: 1-13                             [64, 84]                  [64, 84]                  --\n",
              "├─Linear: 1-14                           [64, 84]                  [64, 10]                  850\n",
              "===================================================================================================================\n",
              "Total params: 107,830\n",
              "Trainable params: 107,830\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 44.87\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 8.14\n",
              "Params size (MB): 0.43\n",
              "Estimated Total Size (MB): 8.77\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Bonus Network\n",
        "summary(bonus,input_size=(batch_size,1,28,28),device=device,col_names=['input_size', 'output_size','num_params'])"
      ],
      "metadata": {
        "id": "_tKgjdjHGsqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "6ce91e4e-e7c2-44e6-df8c-903bf4d86b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
              "===================================================================================================================\n",
              "Bonus                                    [64, 1, 28, 28]           [64, 10]                  --\n",
              "├─Conv2d: 1-1                            [64, 1, 28, 28]           [64, 6, 30, 30]           60\n",
              "├─BatchNorm2d: 1-2                       [64, 6, 30, 30]           [64, 6, 30, 30]           12\n",
              "├─ReLU: 1-3                              [64, 6, 30, 30]           [64, 6, 30, 30]           --\n",
              "├─MaxPool2d: 1-4                         [64, 6, 30, 30]           [64, 6, 15, 15]           --\n",
              "├─Conv2d: 1-5                            [64, 6, 15, 15]           [64, 16, 17, 17]          880\n",
              "├─BatchNorm2d: 1-6                       [64, 16, 17, 17]          [64, 16, 17, 17]          32\n",
              "├─ReLU: 1-7                              [64, 16, 17, 17]          [64, 16, 17, 17]          --\n",
              "├─MaxPool2d: 1-8                         [64, 16, 17, 17]          [64, 16, 8, 8]            --\n",
              "├─Flatten: 1-9                           [64, 16, 8, 8]            [64, 1024]                --\n",
              "├─Linear: 1-10                           [64, 1024]                [64, 256]                 262,400\n",
              "├─ReLU: 1-11                             [64, 256]                 [64, 256]                 --\n",
              "├─Dropout: 1-12                          [64, 256]                 [64, 256]                 --\n",
              "├─Linear: 1-13                           [64, 256]                 [64, 64]                  16,448\n",
              "├─ReLU: 1-14                             [64, 64]                  [64, 64]                  --\n",
              "├─Dropout: 1-15                          [64, 64]                  [64, 64]                  --\n",
              "├─Linear: 1-16                           [64, 64]                  [64, 10]                  650\n",
              "===================================================================================================================\n",
              "Total params: 280,482\n",
              "Trainable params: 280,482\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 37.62\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.20\n",
              "Forward/backward pass size (MB): 10.43\n",
              "Params size (MB): 1.12\n",
              "Estimated Total Size (MB): 11.76\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Which of the models had the least amount of error for validation? How long it took to train each model?"
      ],
      "metadata": {
        "id": "jgQlkQqiEPLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Data From Test Run #1:\n",
        "\n",
        "|Model|Accuracy (Testing data)|Average Test Loss|Time|\n",
        "|-|-|-|-|\n",
        "|Model #1|98.00%|0.458179|5.05 minutes|\n",
        "|Model #2|97.00%|0.488106|5.29 minutes|\n",
        "|Model #3|98.80%|0.064194|5.27 minutes|\n",
        "|Bonus   |98.69%|0.065839|6.00 minutes|\n",
        "\n",
        "\n",
        "Data From Test Run #2:\n",
        "\n",
        "|Model|Accuracy (Testing data)|Average Test Loss|Time|\n",
        "|-|-|-|-|\n",
        "|Model #1|97.95%|0.442075|5.10 minutes|\n",
        "|Model #2|97.31%|0.253610|5.25 minutes|\n",
        "|Model #3|98.76%|0.067962|5.28 minutes|\n",
        "|Bonus   |98.78%|0.063171|6.33 minutes|\n",
        "\n",
        "\n",
        "Data From Test Run #3:\n",
        "\n",
        "|Model|Accuracy (Testing data)|Average Test Loss|Time|\n",
        "|-|-|-|-|\n",
        "|Model #1|97.53%|0.517097|5.57  minutes|\n",
        "|Model #2|97.85%|0.375264|5.76  minutes|\n",
        "|Model #3|98.99%|0.048471|5.74  minutes|\n",
        "|Bonus   |98.74%|0.053674|5.84 minutes|\n",
        "\n",
        "Average From Test Runs:\n",
        "\n",
        "|Model|Accuracy (Testing data)|Average Test Loss|Time|\n",
        "|-|-|-|-|\n",
        "|Model #1|97.83%|0.472450|5.24 minutes|\n",
        "|Model #2|97.39%|0.372327|5.43 minutes|\n",
        "|Model #3|98.85%|0.060209|5.43 minutes|\n",
        "|Bonus   |98.74%|0.060895|6.06 minutes|\n",
        "\n",
        "\n",
        "Each of the models—Model #1, Model #2, Model #3, and the Bonus model—was run through a series of tests to determine their accuracy and average test loss.\n",
        "\n",
        "Accuracy, in this context, refers to the percentage of predictions that the model got correct. For example, if a model has an accuracy of 97.85%, that means it correctly predicted the output 97.85% of the time during testing.\n",
        "\n",
        "On the other hand, the average test loss is a measure of how well the model performs on the test dataset. A lower loss score means the model made fewer errors on the test data, indicating better performance.\n",
        "\n",
        "When comparing the first three models, the **Model#3** performed the best. It had the highest average accuracy across all test runs (98.85%) and the lowest average test loss (0.060209). \n",
        "\n",
        "But when comparing the four models,including the Bonus, we see that the competition of the best model is between the Model#3 and the Bonus. The Bonus had the second highest average accuracy across all test runs (98.74%) and the second lowest average test loss (0.060895). Suggesting that this two models are the most efficient and effective of the four models in this context.\n",
        "\n",
        "In terms of training time, all models took approximately the same amount of time to train—5 minutes each, with the outlier of the Bonus that took 6 minutes.  This means that despite their differences in performance, they all required the same time to train. This could be due to similar amount of training data used."
      ],
      "metadata": {
        "id": "8zMTRvcuEXnz"
      }
    }
  ]
}